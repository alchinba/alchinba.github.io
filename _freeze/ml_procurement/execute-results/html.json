{
  "hash": "cc336d2091cdcbfc3c733661ceafee30",
  "result": {
    "markdown": "---\ntitle: \"Procurement Contracts\"\nexecute: \n    freeze: auto\nformat: \n  html: \n    code-fold: show\n    code-tools: true\n---\n\n\n\n\nI use ML techniques to predict and classify the value of the Procurement Contracts.\n\n## Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nProcurement <- read.csv(\"Procurement.csv\", header=TRUE, sep=\";\")\nView(Procurement)\n```\n:::\n\n\n\n## Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ tibble  3.1.8     ✔ purrr   1.0.1\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(Ecdat)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Ecfun\n\nAttaching package: 'Ecfun'\n\nThe following object is masked from 'package:base':\n\n    sign\n\n\nAttaching package: 'Ecdat'\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n```\n:::\n\n```{.r .cell-code}\nlibrary(glmnet)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-6\n```\n:::\n\n```{.r .cell-code}\nlibrary(Matrix)\n```\n:::\n\n\n\n## Stats\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(Procurement$cri_wb) #NA's 86,535\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    0.25    0.34    0.50    1.00   86535 \n```\n:::\n\n```{.r .cell-code}\nprint(86535/248000) #percent of total obs. Will impute later\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3489315\n```\n:::\n\n```{.r .cell-code}\nprint(248000-86535) #n of total obs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 161465\n```\n:::\n:::\n\n\n\n\n## Cleaning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nProcurement2 = Procurement %>% \n  filter(!is.na(cri_wb))\nsummary(Procurement2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n country_wb_string    country             WBCode          country_iso3      \n Length:161465      Length:161465      Length:161465      Length:161465     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n country_iso2           fyear           year         region         \n Length:161465      Min.   :1998   Min.   :1997   Length:161465     \n Class :character   1st Qu.:2000   1st Qu.:1999   Class :character  \n Mode  :character   Median :2002   Median :2001   Mode  :character  \n                    Mean   :2002   Mean   :2002                     \n                    3rd Qu.:2004   3rd Qu.:2004                     \n                    Max.   :2009   Max.   :2009                     \n                                                                    \n    pr_id             pr_name          pr_loannumber      cft_methodtype    \n Length:161465      Length:161465      Length:161465      Length:161465     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  cft_sector          ca_type            ca_title            ca_id          \n Length:161465      Length:161465      Length:161465      Length:161465     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  ca_nrbidsrec    ca_nrbidscons      ca_contract_value_original\n Min.   :  1.00   Length:161465      Length:161465             \n 1st Qu.:  2.00   Class :character   Class :character          \n Median :  3.00   Mode  :character   Mode  :character          \n Mean   :  5.02                                                \n 3rd Qu.:  6.00                                                \n Max.   :824.00                                                \n NA's   :55151                                                 \n ca_contract_value   lca_contract_value ca_contract_valuec ca_signdate       \n Min.   :0.000e+00   Min.   :-3.632     Length:161465      Length:161465     \n 1st Qu.:5.608e+04   1st Qu.:10.935     Class :character   Class :character  \n Median :2.297e+05   Median :12.345     Mode  :character   Mode  :character  \n Mean   :1.876e+06   Mean   :12.287                                          \n 3rd Qu.:8.755e+05   3rd Qu.:13.683                                          \n Max.   :2.132e+09   Max.   :21.480                                          \n NA's   :13          NA's   :13                                              \n   ca_date           ca_bids_all         ca_bids       ca_procedure      \n Length:161465      Min.   :  1.000   Min.   : 1.000   Length:161465     \n Class :character   1st Qu.:  1.000   1st Qu.: 1.000   Class :character  \n Mode  :character   Median :  2.000   Median : 2.000   Mode  :character  \n                    Mean   :  3.918   Mean   : 3.701                     \n                    3rd Qu.:  4.000   3rd Qu.: 4.000                     \n                    Max.   :993.000   Max.   :50.000                     \n                                                                         \n  ca_signper        ca_signper_corr  ca_signper_corr5   ca_signper_corr25\n Length:161465      Min.   :  0.00   Length:161465      Min.   : 1.00    \n Class :character   1st Qu.: 10.00   Class :character   1st Qu.: 8.00    \n Mode  :character   Median : 27.00   Mode  :character   Median :16.00    \n                    Mean   : 48.92                      Mean   :15.13    \n                    3rd Qu.: 57.00                      3rd Qu.:22.00    \n                    Max.   :728.00                      Max.   :26.00    \n                    NA's   :19568                                        \n    w_name           w_country             w_id             anb_name        \n Length:161465      Length:161465      Length:161465      Length:161465     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    SuppAwd       b2_country         b3_country         b4_country       \n Min.   :1.000   Length:161465      Length:161465      Length:161465     \n 1st Qu.:1.000   Class :character   Class :character   Class :character  \n Median :1.000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :1.049                                                           \n 3rd Qu.:1.000                                                           \n Max.   :7.000                                                           \n                                                                         \n  ppp_original        ppp          country_st            anb_id     \n Min.   :0.108   Min.   :0.1077   Length:161465      Min.   :    1  \n 1st Qu.:0.236   1st Qu.:0.2363   Class :character   1st Qu.: 3775  \n Median :0.306   Median :0.3107   Mode  :character   Median : 6902  \n Mean   :0.330   Mean   :0.3310                      Mean   : 7556  \n 3rd Qu.:0.386   3rd Qu.:0.3865                      3rd Qu.:11454  \n Max.   :1.086   Max.   :1.0864                      Max.   :15600  \n NA's   :6868    NA's   :11                          NA's   :366    \n procedure_type        singleb         prop_bidnr      corr_proc        \n Length:161465      Min.   :0.0000   Min.   :0.0004   Length:161465     \n Class :character   1st Qu.:0.0000   1st Qu.:0.0625   Class :character  \n Mode  :character   Median :0.0000   Median :0.2500   Mode  :character  \n                    Mean   :0.4147   Mean   :0.4676                     \n                    3rd Qu.:1.0000   3rd Qu.:1.0000                     \n                    Max.   :1.0000   Max.   :1.0000                     \n                                                                        \n  corr_proc3         corr_signp        corr_signp1         corr_signp2    \n Length:161465      Length:161465      Length:161465      Min.   :0.0000  \n Class :character   Class :character   Class :character   1st Qu.:0.0000  \n Mode  :character   Mode  :character   Mode  :character   Median :0.0000  \n                                                          Mean   :0.2533  \n                                                          3rd Qu.:1.0000  \n                                                          Max.   :1.0000  \n                                                                          \n  corr_signp3      corr_signp4      corr_proc31     corr_proc32   \n Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.0000   Median :0.0000   Median :1.000   Median :0.000  \n Mean   :0.1148   Mean   :0.1212   Mean   :0.556   Mean   :0.228  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:0.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.000  \n                                                                  \n  corr_proc33         nrc           w_iso             sec_score    \n Min.   :0.000   Min.   :    2   Length:161465      Min.   :31.38  \n 1st Qu.:0.000   1st Qu.: 1707   Class :character   1st Qu.:50.11  \n Median :0.000   Median : 2752   Mode  :character   Median :53.92  \n Mean   :0.216   Mean   : 4989                      Mean   :55.61  \n 3rd Qu.:0.000   3rd Qu.: 6202                      3rd Qu.:58.00  \n Max.   :1.000   Max.   :15701                      Max.   :92.00  \n                                                    NA's   :79897  \n sec_score_max      taxhav          taxhav_fixed         taxhav3         \n Min.   :31.38   Length:161465      Length:161465      Length:161465     \n 1st Qu.:51.00   Class :character   Class :character   Class :character  \n Median :54.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :56.01                                                           \n 3rd Qu.:60.00                                                           \n Max.   :92.00                                                           \n NA's   :84096                                                           \n  taxhav3bi             fsuppl          taxhav31        taxhav32     \n Length:161465      Min.   :0.0000   Min.   :0.000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000  \n Mode  :character   Median :0.0000   Median :0.000   Median :0.0000  \n                    Mean   :0.2568   Mean   :0.237   Mean   :0.0148  \n                    3rd Qu.:1.0000   3rd Qu.:0.000   3rd Qu.:0.0000  \n                    Max.   :1.0000   Max.   :1.000   Max.   :1.0000  \n                                                                     \n    taxhav33           taxhav34          cri_wb      \n Min.   :0.000000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.000000   Median :1.0000   Median :0.2500  \n Mean   :0.005017   Mean   :0.7432   Mean   :0.3419  \n 3rd Qu.:0.000000   3rd Qu.:1.0000   3rd Qu.:0.5000  \n Max.   :1.000000   Max.   :1.0000   Max.   :1.0000  \n                                                     \n```\n:::\n:::\n\n\n## Analysis of Variables\n\nSeeing unique values of categorical vars and descriptive stats of numerical ones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$cft_methodtype)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"National Competitive Bidding\"                 \n [2] \"Single Source Selection\"                      \n [3] \"International Competitive Bidding\"            \n [4] \"Direct Contracting\"                           \n [5] \"Quality And Cost-Based Selection\"             \n [6] \"Limited International Bidding\"                \n [7] \"National Shopping\"                            \n [8] \"International Shopping\"                       \n [9] \"Selection Based On Consultant's Qualification\"\n[10] \"Least Cost Selection\"                         \n[11] \"Quality Based Selection\"                      \n[12] \"Individual\"                                   \n[13] \"Selection Under a Fixed Budget\"               \n[14] \"CQS\"                                          \n[15] \"SHOP\"                                         \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$cft_sector)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Public admin, Law\"    \"Health & social serv\" \"Education\"           \n [4] \"Water/sanit/fld prot\" \"Industry and trade\"   \"Transportation\"      \n [7] \"Finance\"              \"Agriculture\"          \"Energy & mining\"     \n[10] \"Info & communication\" \"(H)\"                  \"(H)Multisector\"      \n[13] \"\"                     \"(H)Priv Sector Dev\"  \n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$cft_sector)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n                                      (H)       (H)Multisector \n                  61                   66                   28 \n  (H)Priv Sector Dev          Agriculture            Education \n                   1                13494                15424 \n     Energy & mining              Finance Health & social serv \n               11106                 4878                25301 \n  Industry and trade Info & communication    Public admin, Law \n                7501                 2067                46307 \n      Transportation Water/sanit/fld prot \n               19215                16016 \n```\n:::\n:::\n\nSector can be divided into dummies later \n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$ca_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Civil Works\"         \"Consultant Services\" \"Goods\"              \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#N of bids recieved\nunique(Procurement2$ca_nrbidsrec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]   6   3   1   5   2   4  NA   7  17  19  10  12   8  11  16   9  21  13  14\n[20]  15  23  27  18 250  25  26  20  22  28  24  40 109  35  70  50  38  36 100\n[39]  56  33  31  58  57  48  45  30  41  79  39  67  65  32  47  54  29  76  34\n[58] 133  64  52  55  78  80 105  44  71 230  43  87  82  69 824  37  46 101 170\n[77] 149\n```\n:::\n\n```{.r .cell-code}\nsummary(Procurement2$ca_nrbidsrec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00    2.00    3.00    5.02    6.00  824.00   55151 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#N of bids considered\n#Was a character class, so transformed into a numerical one\n#Empty spaces treated as if 0\nunique(Procurement2$ca_nrbidscons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"\"    \"1\"   \"2\"   \"3\"   \"5\"   \"4\"   \"7\"   \"6\"   \"88\"  \"13\"  \"8\"   \"12\" \n[13] \"11\"  \"9\"   \"23\"  \"15\"  \"113\" \"143\" \"22\"  \"51\"  \"101\" \"37\"  \"993\" \"102\"\n[25] \"14\"  \"16\"  \"10\"  \"141\" \"886\" \"682\" \"986\" \"20\"  \"21\"  \"31\"  \"26\"  \"17\" \n[37] \"60\" \n```\n:::\n\n```{.r .cell-code}\nsummary(Procurement2$ca_nrbidscons)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Length     Class      Mode \n   161465 character character \n```\n:::\n\n```{.r .cell-code}\nProcurement2 = Procurement2 %>% \n  mutate(bidscons = as.numeric(ca_nrbidscons)) %>% \n  mutate(bidscons = ifelse(is.na(bidscons), 0, bidscons))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#signature period from 14 to 93 days\nProcurement2 = Procurement2 %>% \n  mutate(corr_signp1 = as.numeric(corr_signp1))\n\nsummary(Procurement2$corr_signp1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5107  1.0000  1.0000 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Value of the contract\nProcurement2 = Procurement2 %>% \n  mutate(cntrct_val = as.numeric(ca_contract_value))\n\nsummary(Procurement2$ca_contract_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \n0.000e+00 5.608e+04 2.297e+05 1.876e+06 8.755e+05 2.132e+09        13 \n```\n:::\n\n```{.r .cell-code}\nsummary(Procurement2$cntrct_val)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \n0.000e+00 5.608e+04 2.297e+05 1.876e+06 8.755e+05 2.132e+09        13 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Value of the contract logged\nsummary(Procurement2$lca_contract_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -3.632  10.935  12.345  12.287  13.683  21.480      13 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Contract Value Categories\nunique(Procurement2$ca_contract_valuec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"50.000-199.999\" \"200.000-\"       \"0-24.999\"       \"25.000-49.999\" \n[5] \"\"              \n```\n:::\n\n```{.r .cell-code}\nsummary(Procurement2$ca_contract_valuec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Length     Class      Mode \n   161465 character character \n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$ca_contract_valuec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n                     0-24.999       200.000-  25.000-49.999 50.000-199.999 \n            13          23693          85200          14064          38495 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Main procurement type category\nunique(Procurement2$ca_procedure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"open\"                \"single source\"       \"consultancy,cost\"   \n[4] \"restricted\"          \"consultancy,quality\"\n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$ca_procedure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   consultancy,cost consultancy,quality                open          restricted \n              25508                9372               89770                7637 \n      single source \n              29178 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Signature Period (probably in days)\n#Was character class\nProcurement2 = Procurement2 %>% \n  mutate(signper = as.numeric(ca_signper))\n\nsummary(Procurement2$signper)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \n-29188.00      6.00     23.00     34.83     53.00   2076.00      4436 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Unclear\nunique(Procurement2$SuppAwd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3 4 6 5 7\n```\n:::\n\n```{.r .cell-code}\nsummary(Procurement2$SuppAwd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   1.000   1.000   1.049   1.000   7.000 \n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$SuppAwd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     1      2      3      4      5      6      7 \n155524   4462   1179    199     46     45     10 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Supplier country secrecy score\nsummary(Procurement2$sec_score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  31.38   50.11   53.92   55.61   58.00   92.00   79897 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$procedure_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"National Competitive Bidding\"                 \n [2] \"Single Source Selection\"                      \n [3] \"International Competitive Bidding\"            \n [4] \"Direct Contracting\"                           \n [5] \"Quality And Cost-Based Selection\"             \n [6] \"Limited International Bidding\"                \n [7] \"National Shopping\"                            \n [8] \"International Shopping\"                       \n [9] \"Selection Based On Consultant's Qualification\"\n[10] \"Least Cost Selection\"                         \n[11] \"Quality Based Selection\"                      \n[12] \"Individual\"                                   \n[13] \"Selection Under a Fixed Budget\"               \n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$procedure_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n                           Direct Contracting \n                                         5205 \n                                   Individual \n                                         9782 \n            International Competitive Bidding \n                                        48500 \n                       International Shopping \n                                         4004 \n                         Least Cost Selection \n                                          796 \n                Limited International Bidding \n                                         1896 \n                 National Competitive Bidding \n                                        41270 \n                            National Shopping \n                                         1737 \n             Quality And Cost-Based Selection \n                                        23916 \n                      Quality Based Selection \n                                         2354 \nSelection Based On Consultant's Qualification \n                                         7018 \n               Selection Under a Fixed Budget \n                                          796 \n                      Single Source Selection \n                                        14191 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Whether tax haven or not\nunique(Procurement2$taxhav)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"domestic supplier\" \"NO tax haven\"      \"tax haven\"        \n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$taxhav)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ndomestic supplier      NO tax haven         tax haven \n           119994             38272              3199 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$taxhav_fixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"domestic supplier\" \"NO tax haven\"      \"tax haven\"        \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(Procurement2$taxhav3bi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"domestic supplier\"                   \n[2] \"NO tax haven & tax haven,large state\"\n[3] \"tax haven, small state\"              \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Corruption Risk Index, according to GTI\nsummary(Procurement2$cri_wb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.2500  0.3419  0.5000  1.0000 \n```\n:::\n\n```{.r .cell-code}\nunique(Procurement2$cri_wb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.00 0.25 0.75 0.50 1.00\n```\n:::\n\n```{.r .cell-code}\ntable(Procurement2$cri_wb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    0  0.25   0.5  0.75     1 \n42239 50405 36622 31594   605 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating cri_wb character var for plotting\nProcurement2 = Procurement2 %>% \n  mutate(cri_wb.ch = as.character(cri_wb))\n```\n:::\n\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot cri_wb\nplot(density(Procurement2$cri_wb))\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(hist(Procurement2$cri_wb))\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot distribution\nProcurement2 %>% \n  ggplot(aes(x=cri_wb, colour=region)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot by cri_wb and region\nProcurement2 %>%  \n  group_by(cri_wb.ch, region) %>%  \n  summarize(Count = n()) %>% \n  ggplot(aes(x=region, y=Count, fill=cri_wb.ch)) + \n  geom_bar(stat='identity', position= \"dodge\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'cri_wb.ch'. You can override using the\n`.groups` argument.\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot of lca_contract_value\nplot(density(na.omit(Procurement2$lca_contract_value)))\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot lca_contract_value by region\nProcurement2 %>% \n  ggplot(aes(x=lca_contract_value, color=region)) + \n  geom_density()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 13 rows containing non-finite values (stat_density).\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nWe can observe some differences, for example between regions like Sub-Saharan Africa and Latin America.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot lca_contract_value by sector\nProcurement2 %>% \n  ggplot(aes(x=lca_contract_value, color=cft_sector)) + \n  geom_density()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 13 rows containing non-finite values (stat_density).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Groups with fewer than two data points have been dropped.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nAgain some differences are seen between for example Energy&Mining and Law, which makes sense, since Mining requires more costly equipment. The sector without a name seems to be an outlier almost.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot average lca_contract_value over time\nProcurement2 %>% \n  group_by(year, lca_contract_value) %>% \n  ggplot(aes(y=lca_contract_value, x=year)) +\n  stat_summary(fun = \"mean\", geom = \"line\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 13 rows containing non-finite values (stat_summary).\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nGenerally increasing trend of average value per contract.\n\n## Regression\n\nI run a simple regression with variables of interest to see if anything interesting happens\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Simple Regression for the logged Value\nlr1 = lm(lca_contract_value ~ region + ca_type + ca_bids_all + ca_procedure + singleb + corr_signp2 + corr_signp3 + corr_signp4 + nrc + taxhav_fixed + cri_wb, data = Procurement2)\nsummary(lr1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lca_contract_value ~ region + ca_type + ca_bids_all + \n    ca_procedure + singleb + corr_signp2 + corr_signp3 + corr_signp4 + \n    nrc + taxhav_fixed + cri_wb, data = Procurement2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.4957  -1.2318   0.0867   1.2818   8.4553 \n\nCoefficients: (1 not defined because of singularities)\n                                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                      1.358e+01  3.544e-02 383.279  < 2e-16 ***\nregionEAP                       -5.604e-02  1.851e-02  -3.028  0.00247 ** \nregionECA                       -2.158e-01  1.546e-02 -13.959  < 2e-16 ***\nregionLCR                       -5.246e-01  1.536e-02 -34.153  < 2e-16 ***\nregionMNA                        8.887e-02  2.102e-02   4.227 2.37e-05 ***\nregionSAR                       -5.903e-02  2.073e-02  -2.848  0.00441 ** \nca_typeConsultant Services      -1.443e+00  3.071e-02 -46.986  < 2e-16 ***\nca_typeGoods                    -7.299e-01  1.279e-02 -57.051  < 2e-16 ***\nca_bids_all                      6.982e-04  3.591e-04   1.945  0.05184 .  \nca_procedureconsultancy,quality -9.478e-01  2.372e-02 -39.965  < 2e-16 ***\nca_procedureopen                -6.071e-01  3.322e-02 -18.277  < 2e-16 ***\nca_procedurerestricted          -1.573e+00  3.941e-02 -39.906  < 2e-16 ***\nca_proceduresingle source       -7.534e-01  1.824e-02 -41.302  < 2e-16 ***\nsingleb                         -1.965e-01  1.232e-02 -15.949  < 2e-16 ***\ncorr_signp2                     -2.161e-01  1.201e-02 -17.986  < 2e-16 ***\ncorr_signp3                      2.122e-01  1.592e-02  13.331  < 2e-16 ***\ncorr_signp4                     -5.635e-01  1.590e-02 -35.452  < 2e-16 ***\nnrc                              4.125e-05  1.467e-06  28.117  < 2e-16 ***\ntaxhav_fixedNO tax haven         8.181e-01  1.238e-02  66.078  < 2e-16 ***\ntaxhav_fixedtax haven            8.470e-01  3.503e-02  24.176  < 2e-16 ***\ncri_wb                                  NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.935 on 161432 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.1659,\tAdjusted R-squared:  0.1658 \nF-statistic:  1690 on 19 and 161432 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAdjusted R-squared is about 0.17, whereas cri_wb is dropped because of singularity. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndeviance(lr1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 604717.7\n```\n:::\n:::\n\n\nRSS is quite big.\n\nThe variable for cri_wb was omitted due to singularities. Perhaps creating a dummy might change it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating cri_wb dummy\n#0.00 0.25 0.75 0.50 1.00\nProcurement2 = Procurement2 %>% \n  mutate(cri_wb.d0 = ifelse(cri_wb==0, 1, 0)) %>% \n  mutate(cri_wb.d25 = ifelse(cri_wb==0.25, 1, 0)) %>%\n  mutate(cri_wb.d50 = ifelse(cri_wb==0.5, 1, 0)) %>%\n  mutate(cri_wb.d75 = ifelse(cri_wb==0.75, 1, 0))\n```\n:::\n\n\nI am creating several dummies for categorical vars.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating cft_sector dummmies, omitting \"\"\nProcurement2 = Procurement2 %>% \n  mutate(P = ifelse(cft_sector==\"Public admin, Law\", 1, 0)) %>% \n  mutate(Health = ifelse(cft_sector==\"Health & social serv\", 1, 0)) %>%\n  mutate(Edu = ifelse(cft_sector==\"Education\", 1, 0)) %>%\n  mutate(W = ifelse(cft_sector==\"Water/sanit/fld prot\", 1, 0)) %>%\n  mutate(I = ifelse(cft_sector==\"Industry and trade\", 1, 0)) %>%\n  mutate(Tran = ifelse(cft_sector==\"Transportation\", 1, 0)) %>% \n  mutate(Fin = ifelse(cft_sector==\"Finance\", 1, 0)) %>% \n  mutate(A = ifelse(cft_sector==\"Agriculture\", 1, 0)) %>%\n  mutate(Ener = ifelse(cft_sector==\"Energy & mining\", 1, 0)) %>%\n  mutate(Info = ifelse(cft_sector==\"Info & communication\", 1, 0)) %>%\n  mutate(H = ifelse(cft_sector==\"(H)\", 1, 0)) %>%\n  mutate(Multi = ifelse(cft_sector==\"(H)Multisector\", 1, 0)) %>% \n  mutate(Priv = ifelse(cft_sector==\"(H)Priv Sector Dev\", 1, 0))\nunique(Procurement2$cft_sector)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Public admin, Law\"    \"Health & social serv\" \"Education\"           \n [4] \"Water/sanit/fld prot\" \"Industry and trade\"   \"Transportation\"      \n [7] \"Finance\"              \"Agriculture\"          \"Energy & mining\"     \n[10] \"Info & communication\" \"(H)\"                  \"(H)Multisector\"      \n[13] \"\"                     \"(H)Priv Sector Dev\"  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nProcurement2 = Procurement2 %>% \n  mutate(AFR = ifelse(region==\"AFR\", 1, 0)) %>% \n  mutate(EAP = ifelse(region==\"EAP\", 1, 0)) %>%\n  mutate(ECA = ifelse(region==\"ECA\", 1, 0)) %>%\n  mutate(LCR = ifelse(region==\"LCR\", 1, 0)) %>%\n  mutate(MNA = ifelse(region==\"MNA\", 1, 0)) %>%\n  mutate(SAR = ifelse(region==\"SAR\", 1, 0))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating ca_type dummies, omitting Civil Works\nProcurement2 = Procurement2 %>% \n  mutate(ca_Consul.Service = ifelse(ca_type==\"Consultant Services\", 1, 0)) %>% \n  mutate(ca_Goods = ifelse(ca_type==\"Goods\", 1, 0))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating taxhav_fixed dummies, omitting domestric supplier\nProcurement2 = Procurement2 %>% \n  mutate(not.taxhaven = ifelse(taxhav_fixed==\"NO tax haven\", 1, 0)) %>% \n  mutate(taxhaven = ifelse(taxhav_fixed==\"tax haven\", 1, 0))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating ca_procedure dummies, omitting cost\nProcurement2 = Procurement2 %>% \n  mutate(ca_proc_open = ifelse(ca_procedure==\"open\", 1, 0)) %>% \n  mutate(ca_proc_quality = ifelse(ca_procedure==\"consultancy,quality\", 1, 0)) %>%\n  mutate(ca_proc_source = ifelse(ca_procedure==\"single source\", 1, 0)) %>%\n  mutate(ca_proc_restricted = ifelse(ca_procedure==\"restricted\", 1, 0))\n```\n:::\n\n\nFor regression of the value per contract I am selecting the following variables:\n  1. Dummy variables for region, because there was a slight difference between the distributions of value by regions.\n  4. Procurement Sector, thinking some sectors tend to attract more valuable tender contracts.\n  2. Dummy for ca_type (Procurement Category) since the type of services can affect the value\n  3. Dummy for for n of bidders since higher n of bidders should indicate a higher price of the contract.\n  4. Dummy for contract award procedure associated with corruption.\n  5. Dummy for single bidder might indicate corrupted case, which can imply high value of the contract.\n  6. Period between when the contract was awarded and signed.\n  7. Number of contracts per country.\n  8. Whether the supplier is a domestic one or a tax haven. Foreign tax havens might indicate corruption and thus higher price.\n  9. The Corruption Index might be associated with the higher value of the contract.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating only predictor and response dataset Procurement3\nProcurement3 = Procurement2 %>% \n  select(\"ca_contract_valuec\", \"lca_contract_value\", \"AFR\", \"EAP\", \"ECA\", \"LCR\", \"MNA\", \"SAR\", \"ca_Consul.Service\", \"ca_Goods\", \"ca_bids_all\", \"ca_proc_open\", \"ca_proc_quality\", \"ca_proc_source\", \"ca_proc_restricted\", \"singleb\", \"corr_signp1\", \"corr_signp2\", \"corr_signp3\", \"nrc\", \"taxhaven\", \"not.taxhaven\", \"cri_wb.d0\", \"cri_wb.d25\", \"cri_wb.d50\", \"cri_wb.d75\", \"P\", \"Health\", \"Edu\", \"W\", \"I\", \"Tran\", \"Fin\", \"A\", \"Ener\", \"Info\", \"H\", \"Multi\", \"Priv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Saving Procurement3 as an excel dataset\nlibrary(writexl)\nwrite_xlsx(Procurement3, \"~/Desktop/BC_courses/BigDataEconometrics/Procurement3.xlsx\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Omitting any missing values\nProcurement3 = na.omit(Procurement3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Linear Regression with Procurement3\nlr2 = lm(lca_contract_value ~ ., data = Procurement3)\nsummary(lr2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lca_contract_value ~ ., data = Procurement3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.7818  -0.6101  -0.0397   0.5108   7.0744 \n\nCoefficients: (2 not defined because of singularities)\n                                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       9.252e+00  1.382e-01  66.933  < 2e-16 ***\nca_contract_valuec200.000-        4.692e+00  7.916e-03 592.686  < 2e-16 ***\nca_contract_valuec25.000-49.999   1.543e+00  1.066e-02 144.820  < 2e-16 ***\nca_contract_valuec50.000-199.999  2.570e+00  8.370e-03 307.066  < 2e-16 ***\nAFR                               5.303e-02  1.071e-02   4.951 7.40e-07 ***\nEAP                               1.428e-01  9.106e-03  15.681  < 2e-16 ***\nECA                               6.290e-02  1.089e-02   5.778 7.57e-09 ***\nLCR                               1.050e-01  1.050e-02  10.000  < 2e-16 ***\nMNA                               1.890e-01  1.336e-02  14.146  < 2e-16 ***\nSAR                                      NA         NA      NA       NA    \nca_Consul.Service                -3.435e-01  1.593e-02 -21.562  < 2e-16 ***\nca_Goods                         -2.349e-01  6.761e-03 -34.744  < 2e-16 ***\nca_bids_all                       1.069e-03  1.850e-04   5.782 7.40e-09 ***\nca_proc_open                      2.515e-01  4.851e-02   5.184 2.17e-07 ***\nca_proc_quality                  -1.505e-01  1.232e-02 -12.215  < 2e-16 ***\nca_proc_source                   -6.125e-02  9.609e-03  -6.374 1.85e-10 ***\nca_proc_restricted               -2.147e-01  2.046e-02 -10.492  < 2e-16 ***\nsingleb                          -2.465e-01  4.567e-02  -5.398 6.74e-08 ***\ncorr_signp1                       3.224e-01  4.605e-02   7.001 2.55e-12 ***\ncorr_signp2                       4.846e-02  8.781e-03   5.519 3.42e-08 ***\ncorr_signp3                       2.146e-01  1.054e-02  20.355  < 2e-16 ***\nnrc                               1.587e-05  7.593e-07  20.903  < 2e-16 ***\ntaxhaven                          1.119e-01  4.103e-02   2.728 0.006376 ** \nnot.taxhaven                      2.798e-01  6.462e-03  43.304  < 2e-16 ***\ncri_wb.d0                        -6.546e-01  1.366e-01  -4.791 1.66e-06 ***\ncri_wb.d25                       -5.129e-01  9.156e-02  -5.602 2.12e-08 ***\ncri_wb.d50                       -2.489e-01  4.666e-02  -5.334 9.61e-08 ***\ncri_wb.d75                               NA         NA      NA       NA    \nP                                -2.145e-01  1.278e-01  -1.678 0.093383 .  \nHealth                           -9.958e-02  1.279e-01  -0.779 0.436187    \nEdu                              -9.031e-02  1.280e-01  -0.706 0.480466    \nW                                 2.929e-02  1.280e-01   0.229 0.819010    \nI                                -1.220e-01  1.282e-01  -0.952 0.341306    \nTran                              3.261e-01  1.280e-01   2.549 0.010814 *  \nFin                              -9.101e-02  1.285e-01  -0.708 0.478748    \nA                                -4.242e-02  1.280e-01  -0.331 0.740364    \nEner                              3.031e-01  1.281e-01   2.366 0.017991 *  \nInfo                             -1.693e-01  1.296e-01  -1.306 0.191443    \nH                                -6.562e-02  1.771e-01  -0.371 0.710976    \nMulti                            -8.459e-01  2.276e-01  -3.717 0.000202 ***\nPriv                              5.614e-01  1.005e+00   0.559 0.576349    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9966 on 161413 degrees of freedom\nMultiple R-squared:  0.7789,\tAdjusted R-squared:  0.7788 \nF-statistic: 1.496e+04 on 38 and 161413 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nTwo variables were dropped because of singularity still. Most of the remaining vars have high statistical significance.\n\n\n\n## Ridge Regression with Grid Search\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Last check of the predictor dataset\nsummary(Procurement3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n ca_contract_valuec lca_contract_value      AFR             EAP        \n Length:161452      Min.   :-3.632     Min.   :0.000   Min.   :0.0000  \n Class :character   1st Qu.:10.935     1st Qu.:0.000   1st Qu.:0.0000  \n Mode  :character   Median :12.345     Median :0.000   Median :0.0000  \n                    Mean   :12.287     Mean   :0.232   Mean   :0.1787  \n                    3rd Qu.:13.683     3rd Qu.:0.000   3rd Qu.:0.0000  \n                    Max.   :21.480     Max.   :1.000   Max.   :1.0000  \n      ECA              LCR              MNA               SAR        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000  \n Mean   :0.1791   Mean   :0.1975   Mean   :0.07035   Mean   :0.1424  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n ca_Consul.Service    ca_Goods       ca_bids_all       ca_proc_open  \n Min.   :0.0000    Min.   :0.0000   Min.   :  1.000   Min.   :0.000  \n 1st Qu.:0.0000    1st Qu.:0.0000   1st Qu.:  1.000   1st Qu.:0.000  \n Median :0.0000    Median :0.0000   Median :  2.000   Median :1.000  \n Mean   :0.3645    Mean   :0.3459   Mean   :  3.918   Mean   :0.556  \n 3rd Qu.:1.0000    3rd Qu.:1.0000   3rd Qu.:  4.000   3rd Qu.:1.000  \n Max.   :1.0000    Max.   :1.0000   Max.   :993.000   Max.   :1.000  \n ca_proc_quality   ca_proc_source   ca_proc_restricted    singleb      \n Min.   :0.00000   Min.   :0.0000   Min.   :0.0000     Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000     1st Qu.:0.0000  \n Median :0.00000   Median :0.0000   Median :0.0000     Median :0.0000  \n Mean   :0.05805   Mean   :0.1806   Mean   :0.0473     Mean   :0.4147  \n 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000     3rd Qu.:1.0000  \n Max.   :1.00000   Max.   :1.0000   Max.   :1.0000     Max.   :1.0000  \n  corr_signp1      corr_signp2      corr_signp3          nrc       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :    2  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 1707  \n Median :1.0000   Median :0.0000   Median :0.0000   Median : 2752  \n Mean   :0.5108   Mean   :0.2532   Mean   :0.1148   Mean   : 4990  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.: 6202  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :15701  \n    taxhaven       not.taxhaven     cri_wb.d0        cri_wb.d25    \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :0.0000  \n Mean   :0.0198   Mean   :0.237   Mean   :0.2616   Mean   :0.3122  \n 3rd Qu.:0.0000   3rd Qu.:0.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   cri_wb.d50       cri_wb.d75           P              Health      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.2268   Mean   :0.1956   Mean   :0.2868   Mean   :0.1567  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n      Edu                W                 I                Tran      \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.000  \n Mean   :0.09553   Mean   :0.09919   Mean   :0.04646   Mean   :0.119  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.000  \n      Fin                A               Ener              Info       \n Min.   :0.00000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.00000   Median :0.0000   Median :0.00000   Median :0.0000  \n Mean   :0.03021   Mean   :0.0835   Mean   :0.06879   Mean   :0.0128  \n 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.00000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n       H                 Multi                Priv        \n Min.   :0.0000000   Min.   :0.0000000   Min.   :0.0e+00  \n 1st Qu.:0.0000000   1st Qu.:0.0000000   1st Qu.:0.0e+00  \n Median :0.0000000   Median :0.0000000   Median :0.0e+00  \n Mean   :0.0004088   Mean   :0.0001734   Mean   :6.2e-06  \n 3rd Qu.:0.0000000   3rd Qu.:0.0000000   3rd Qu.:0.0e+00  \n Max.   :1.0000000   Max.   :1.0000000   Max.   :1.0e+00  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#assigning index to each row\nindex = 1:nrow(Procurement3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#randomly taking 90% of the indices for training subset\nset.seed(12345) #for random\ntrain_index = sample(index, round(0.90*nrow(Procurement3)), replace = FALSE) #takes sample of 90% of rows without replacement\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#taking the remaining indices for test subset\ntest_index = setdiff(index, train_index) #takes untaken rows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating train and test subsets of obs\ntrain_x = Procurement3[train_index, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec, -starts_with(\"cri_wb.d\")) #Procurement3[train_index, ] expression to use only training subset %>% everything except price, price category, and corruption index\n\ntrain_y = Procurement3[train_index, ] %>% \n  pull(lca_contract_value)\n\ntest_x = Procurement3[test_index, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec, -starts_with(\"cri_wb.d\"))\n\ntest_y = Procurement3[test_index, ] %>% \n  pull(lca_contract_value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#putting subsets into matrices for the models\n#creates a model) matrix, e.g., by expanding factors to a set of dummy variables (depending on the contrasts) and expanding interactions similarly.\ntrain_matrix = model.matrix(train_y ~ ., data = train_x)\n\ntest_matrix = model.matrix(test_y ~ ., data = test_x)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Linear Regression\n#To run an unpenalized linear regression penalty, lambda is set to 0\nmodel_lm_ridge = glmnet(y = train_y, x = train_matrix, alpha = 0, lambda = 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Coefficients\ncoef(model_lm_ridge)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n35 x 1 sparse Matrix of class \"dgCMatrix\"\n                              s0\n(Intercept)         1.295066e+01\n(Intercept)         .           \nAFR                 1.740151e-01\nEAP                 5.540119e-02\nECA                -5.063949e-03\nLCR                -2.871303e-01\nMNA                 3.080603e-01\nSAR                 1.182342e-01\nca_Consul.Service  -1.243931e+00\nca_Goods           -6.270021e-01\nca_bids_all         9.673877e-04\nca_proc_open       -4.830663e-01\nca_proc_quality    -8.910647e-01\nca_proc_source     -7.194468e-01\nca_proc_restricted -1.445686e+00\nsingleb            -1.378996e-01\ncorr_signp1         5.353419e-01\ncorr_signp2         3.257312e-01\ncorr_signp3         7.423295e-01\nnrc                 3.892206e-05\ntaxhaven            8.405527e-01\nnot.taxhaven        8.169726e-01\nP                  -9.535187e-01\nHealth             -3.615957e-01\nEdu                -7.520389e-02\nW                   9.985832e-03\nI                  -6.340170e-01\nTran                4.970437e-01\nFin                -6.351149e-01\nA                   3.418690e-02\nEner                5.531834e-01\nInfo               -8.652731e-01\nH                  -1.507041e-01\nMulti              -5.725173e-01\nPriv                1.060161e+00\n```\n:::\n:::\n\n\nCoefficients of this regression did not drop the two from the lr2, which might be because the estimates in glmnet and lm will never be exactly the same and one is the subset of the other.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#RMSE for lm\n#compute the RMSE\npreds_lm = predict(model_lm_ridge, test_matrix)\n\nrmse_lm = sqrt(mean(preds_lm - test_y)^2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Ridge regression with lambda 10\nmodel_ridge = glmnet(y = train_y, x = train_matrix, alpha = 0, lambda = 10)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#compute the RMSE for Ridge\npreds = predict(model_ridge, test_matrix)\n\nrmse = sqrt(mean(preds - test_y)^2)\n```\n:::\n\n\nRMSE of the first Ridge regression is bigger than that of the unregularized linear regression. Seems that the optimal lambda should be small.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#finding optimal lambda\n#Function for picking the lowest RMSE\n#cv.glmnet: Does k-fold cross-validation for glmnet, produces a plot, and returns a value for lambda\nbest_model = cv.glmnet(train_matrix, train_y, alpha=0)\n# lambda that minimizes the MSE\nbest_model$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05474761\n```\n:::\n:::\n\n\nThe optimal lambda is very close to 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Ridge regression with optimal lambda\n#use the new lambda\nnew_lambda = best_model$lambda.min\nnew_model_ridge = glmnet(y = train_y, x = train_matrix, alpha = 0, lambda = new_lambda)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#new RMSE\n#check the RMSE\nnew_preds = predict(new_model_ridge, test_matrix)\n\nnew_rmse = sqrt(mean(new_preds - test_y)^2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Comparing RMSE\nprint(rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01582965\n```\n:::\n\n```{.r .cell-code}\nprint(rmse_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01447194\n```\n:::\n\n```{.r .cell-code}\nprint(new_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01409955\n```\n:::\n:::\n\n\n\n\nThe RMSE for Ridge regression with the optimal parameter is smaller than that with lambda 0 just a little bit. Which means regularized regression is just a little more efficient than the simple linear regression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Comparing RSS\nsse_lm = sum((preds_lm - test_y)^2)\nsse_ridge = sum((new_preds - test_y)^2)\n\nprint(sse_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 56996.77\n```\n:::\n\n```{.r .cell-code}\nprint(sse_ridge)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 57044.26\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlr3 = lm(train_y ~ ., data = train_x)\nsummary(lr3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y ~ ., data = train_x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.9811  -1.1631   0.0784   1.2355   8.4591 \n\nCoefficients: (1 not defined because of singularities)\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         1.231e+01  2.672e-01  46.051  < 2e-16 ***\nAFR                 5.563e-02  2.107e-02   2.640 0.008280 ** \nEAP                -6.235e-02  1.788e-02  -3.488 0.000488 ***\nECA                -1.228e-01  2.140e-02  -5.735 9.75e-09 ***\nLCR                -4.057e-01  2.058e-02 -19.717  < 2e-16 ***\nMNA                 1.897e-01  2.630e-02   7.215 5.40e-13 ***\nSAR                        NA         NA      NA       NA    \nca_Consul.Service  -1.254e+00  3.123e-02 -40.153  < 2e-16 ***\nca_Goods           -6.273e-01  1.324e-02 -47.388  < 2e-16 ***\nca_bids_all         9.722e-04  3.647e-04   2.666 0.007686 ** \nca_proc_open       -4.938e-01  3.371e-02 -14.650  < 2e-16 ***\nca_proc_quality    -8.915e-01  2.411e-02 -36.982  < 2e-16 ***\nca_proc_source     -7.207e-01  1.854e-02 -38.863  < 2e-16 ***\nca_proc_restricted -1.456e+00  3.999e-02 -36.409  < 2e-16 ***\nsingleb            -1.378e-01  1.251e-02 -11.009  < 2e-16 ***\ncorr_signp1         5.356e-01  1.612e-02  33.230  < 2e-16 ***\ncorr_signp2         3.258e-01  1.724e-02  18.900  < 2e-16 ***\ncorr_signp3         7.424e-01  2.055e-02  36.121  < 2e-16 ***\nnrc                 3.891e-05  1.493e-06  26.061  < 2e-16 ***\ntaxhaven            8.407e-01  3.551e-02  23.672  < 2e-16 ***\nnot.taxhaven        8.168e-01  1.261e-02  64.770  < 2e-16 ***\nP                  -1.791e-01  2.635e-01  -0.679 0.496886    \nHealth              4.127e-01  2.637e-01   1.565 0.117569    \nEdu                 6.990e-01  2.639e-01   2.649 0.008080 ** \nW                   7.842e-01  2.639e-01   2.972 0.002962 ** \nI                   1.401e-01  2.643e-01   0.530 0.596089    \nTran                1.271e+00  2.638e-01   4.818 1.45e-06 ***\nFin                 1.388e-01  2.648e-01   0.524 0.600193    \nA                   8.082e-01  2.639e-01   3.062 0.002199 ** \nEner                1.327e+00  2.641e-01   5.026 5.03e-07 ***\nInfo               -9.151e-02  2.669e-01  -0.343 0.731706    \nH                   6.233e-01  3.608e-01   1.728 0.084042 .  \nMulti               2.018e-01  4.622e-01   0.437 0.662471    \nPriv                1.833e+00  1.879e+00   0.976 0.329313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.861 on 145274 degrees of freedom\nMultiple R-squared:  0.2276,\tAdjusted R-squared:  0.2275 \nF-statistic:  1338 on 32 and 145274 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_lr3 = predict(lr3, test_x)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(lr3, test_x): prediction from a rank-deficient fit may be\nmisleading\n```\n:::\n\n```{.r .cell-code}\nrmse_lr3 = sqrt(mean(preds_lr3 - test_y)^2)\nsum((preds_lr3 - test_y)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 56998.57\n```\n:::\n:::\n\n\n\nResidual Sums Squared are almost identical for both regressions. Given that, I'd suggest sticking to a simpler model, i.e. unpenalized Linear Regression Model.\n\n\n## Corrected Ridge without cri_wb\n\nLater in the research I discovered that cri_wb caused multicollinearity, so I removed it and performed Ridge regression again\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#subsetting the data\n\nindex.r = 1:nrow(Procurement3) #indexing each row\n\nset.seed(12345) #for random\ntrain_index.r = sample(index.r, round(0.90*nrow(Procurement3)), replace = FALSE) #takes sample of 90% of rows without replacement\n\ntest_index.r = setdiff(index.r, train_index.r) #takes untaken rows\n\ntrain_x.r = Procurement3[train_index.r, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec, -starts_with(\"cri_wb.d\")) #Procurement3[train_index, ] expression to use only training subset %>% everything except price, price category, and corruption index\n\ntrain_y.r = Procurement3[train_index.r, ] %>% \n  pull(lca_contract_value)\n\ntest_x.r = Procurement3[test_index.r, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec, -starts_with(\"cri_wb.d\"))\n\ntest_y.r = Procurement3[test_index.r, ] %>% \n  pull(lca_contract_value)\n\n#creates a model) matrix, e.g., by expanding factors to a set of dummy variables (depending on the contrasts) and expanding interactions similarly. The matrices are for glmnet.\ntrain_matrix.r = model.matrix(train_y.r ~ ., data = train_x.r)\n\ntest_matrix.r = model.matrix(test_y.r ~ ., data = test_x.r)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#CORRECTED Linear Regression with glmnet\n#To run an unpenalized linear regression penalty, lambda is set to 0\nlm_ridge.c = glmnet(y = train_y.r, x = train_matrix.r, alpha = 0, lambda = 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#RMSE and SSE for corrected lm glmnet\npreds_r = predict(lm_ridge.c, test_matrix.r)\n\nrmse_r = sqrt(mean(preds_r - test_y.r)^2)\nsse_r = sum((preds_r - test_y.r)^2)\n\nprint(rmse_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01447194\n```\n:::\n\n```{.r .cell-code}\nprint(sse_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 56996.77\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#finding optimal lambda\n\n#Function for picking the lowest RMSE\n#cv.glmnet: Does k-fold cross-validation for glmnet, produces a plot, and returns a value for lambda\nbest_model.r = cv.glmnet(train_matrix.r, train_y.r, alpha=0)\n# lambda that minimizes the MSE\nbest_model.r$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05474761\n```\n:::\n:::\n\n\nThe optimal lambda is very close to 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Ridge regression with optimal lambda\n#use the new lambda\nnew_lambda.r = best_model.r$lambda.min\nlm_ridge.c2 = glmnet(y = train_y.r, x = train_matrix.r, alpha = 0, lambda = new_lambda.r)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#new RMSE\n#check the RMSE\nnew_preds.r = predict(lm_ridge.c2, test_matrix.r)\n\nnew_rmse.r = sqrt(mean(new_preds.r - test_y.r)^2)\nnew_sse.r = sum((new_preds.r - test_y.r)^2)\n\nprint(new_rmse.r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01409955\n```\n:::\n\n```{.r .cell-code}\nprint(new_sse.r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 57044.26\n```\n:::\n:::\n\n\n\n## Logit for contract value categories\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating contract_valuec dummy and Procurement4\nProcurement4 = Procurement3 %>% \n  mutate(value.cat = ifelse(ca_contract_valuec==\"200.000-\", 1, 0)) %>% \n  select(-c(ca_contract_valuec, lca_contract_value)) #I drop cols for value logged and category\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#simple logit model\nlog_model = glm(value.cat ~ ., family = binomial(link = \"logit\"), Procurement4)\nsummary(log_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = value.cat ~ ., family = binomial(link = \"logit\"), \n    data = Procurement4)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1680  -1.0435   0.5946   0.9686   2.4301  \n\nCoefficients: (2 not defined because of singularities)\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         2.173e-01  3.725e-01   0.583 0.559751    \nAFR                -1.557e-01  2.348e-02  -6.632 3.32e-11 ***\nEAP                -2.572e-01  2.025e-02 -12.697  < 2e-16 ***\nECA                -2.847e-01  2.384e-02 -11.941  < 2e-16 ***\nLCR                -6.262e-01  2.302e-02 -27.201  < 2e-16 ***\nMNA                -8.363e-02  2.911e-02  -2.873 0.004065 ** \nSAR                        NA         NA      NA       NA    \nca_Consul.Service  -1.132e+00  3.419e-02 -33.102  < 2e-16 ***\nca_Goods           -4.248e-01  1.462e-02 -29.046  < 2e-16 ***\nca_bids_all         3.636e-04  4.081e-04   0.891 0.372981    \nca_proc_open       -2.588e-01  1.072e-01  -2.414 0.015777 *  \nca_proc_quality    -7.728e-01  2.734e-02 -28.270  < 2e-16 ***\nca_proc_source     -8.616e-01  2.107e-02 -40.888  < 2e-16 ***\nca_proc_restricted -1.399e+00  4.401e-02 -31.799  < 2e-16 ***\nsingleb            -4.436e-01  1.012e-01  -4.381 1.18e-05 ***\ncorr_signp1         8.260e-01  1.021e-01   8.090 5.98e-16 ***\ncorr_signp2         3.143e-01  1.952e-02  16.099  < 2e-16 ***\ncorr_signp3         6.527e-01  2.323e-02  28.100  < 2e-16 ***\nnrc                 2.967e-05  1.669e-06  17.774  < 2e-16 ***\ntaxhaven            4.303e-01  9.095e-02   4.731 2.23e-06 ***\nnot.taxhaven        6.952e-01  1.412e-02  49.228  < 2e-16 ***\ncri_wb.d0          -9.895e-01  3.031e-01  -3.265 0.001095 ** \ncri_wb.d25         -7.253e-01  2.031e-01  -3.572 0.000354 ***\ncri_wb.d50         -3.457e-01  1.035e-01  -3.341 0.000834 ***\ncri_wb.d75                 NA         NA      NA       NA    \nP                   3.103e-01  3.543e-01   0.876 0.381088    \nHealth              9.720e-01  3.544e-01   2.743 0.006092 ** \nEdu                 1.355e+00  3.545e-01   3.822 0.000132 ***\nW                   1.275e+00  3.545e-01   3.596 0.000323 ***\nI                   6.389e-01  3.550e-01   1.800 0.071878 .  \nTran                1.641e+00  3.545e-01   4.629 3.68e-06 ***\nFin                 7.281e-01  3.554e-01   2.049 0.040501 *  \nA                   1.378e+00  3.546e-01   3.885 0.000102 ***\nEner                1.716e+00  3.548e-01   4.837 1.32e-06 ***\nInfo                3.506e-01  3.573e-01   0.981 0.326468    \nH                   1.121e+00  4.383e-01   2.557 0.010551 *  \nMulti               2.200e+00  5.811e-01   3.786 0.000153 ***\nPriv                7.657e+00  2.667e+01   0.287 0.774001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 223324  on 161451  degrees of freedom\nResidual deviance: 195143  on 161416  degrees of freedom\nAIC: 195215\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating train and test dataset\n\nindex.log = 1:nrow(Procurement4)\n\nset.seed(12345) #for random\ntrain_index.log = sample(index.log, round(0.90*nrow(Procurement4)), replace = FALSE) #takes sample of 90% of rows without replacement\n\ntest_index.log = setdiff(index.log, train_index.log) #takes remaining rows for test\n\n#creating train and test subsets of obs\ntrain_x.log = Procurement4[train_index.log, ] %>% \n  select(-value.cat) #Procurement3[train_index.log, ] expression to use only training subset %>% everything except price category\n\ntrain_y.log = Procurement4[train_index.log, ] %>% \n  pull(value.cat) #pulls only value.cat\n\ntest_x.log = Procurement4[test_index.log, ] %>% \n  select(-value.cat)\n\ntest_y.log = Procurement4[test_index.log, ] %>% \n  pull(value.cat)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#logit model training\n\nlog_model_train = glm(train_y.log ~ ., family = binomial(link = \"logit\"), train_x.log)\nsummary(log_model_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = train_y.log ~ ., family = binomial(link = \"logit\"), \n    data = train_x.log)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1717  -1.0427   0.5951   0.9680   2.4297  \n\nCoefficients: (2 not defined because of singularities)\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         1.446e-01  4.138e-01   0.349 0.726831    \nAFR                -1.496e-01  2.475e-02  -6.045 1.49e-09 ***\nEAP                -2.556e-01  2.132e-02 -11.987  < 2e-16 ***\nECA                -2.766e-01  2.514e-02 -11.005  < 2e-16 ***\nLCR                -6.208e-01  2.426e-02 -25.591  < 2e-16 ***\nMNA                -6.703e-02  3.071e-02  -2.183 0.029056 *  \nSAR                        NA         NA      NA       NA    \nca_Consul.Service  -1.121e+00  3.604e-02 -31.096  < 2e-16 ***\nca_Goods           -4.294e-01  1.541e-02 -27.856  < 2e-16 ***\nca_bids_all         3.483e-04  4.278e-04   0.814 0.415608    \nca_proc_open       -2.637e-01  1.128e-01  -2.338 0.019403 *  \nca_proc_quality    -7.794e-01  2.887e-02 -26.995  < 2e-16 ***\nca_proc_source     -8.612e-01  2.224e-02 -38.728  < 2e-16 ***\nca_proc_restricted -1.396e+00  4.643e-02 -30.069  < 2e-16 ***\nsingleb            -4.285e-01  1.065e-01  -4.025 5.70e-05 ***\ncorr_signp1         8.177e-01  1.073e-01   7.620 2.54e-14 ***\ncorr_signp2         3.158e-01  2.057e-02  15.352  < 2e-16 ***\ncorr_signp3         6.552e-01  2.447e-02  26.772  < 2e-16 ***\nnrc                 2.977e-05  1.760e-06  16.917  < 2e-16 ***\ntaxhaven            4.361e-01  9.553e-02   4.565 5.00e-06 ***\nnot.taxhaven        6.971e-01  1.491e-02  46.765  < 2e-16 ***\ncri_wb.d0          -9.462e-01  3.186e-01  -2.970 0.002982 ** \ncri_wb.d25         -7.003e-01  2.135e-01  -3.280 0.001037 ** \ncri_wb.d50         -3.246e-01  1.088e-01  -2.983 0.002850 ** \ncri_wb.d75                 NA         NA      NA       NA    \nP                   3.490e-01  3.955e-01   0.882 0.377560    \nHealth              1.020e+00  3.956e-01   2.579 0.009897 ** \nEdu                 1.398e+00  3.958e-01   3.533 0.000411 ***\nW                   1.311e+00  3.958e-01   3.313 0.000924 ***\nI                   6.749e-01  3.962e-01   1.704 0.088465 .  \nTran                1.680e+00  3.957e-01   4.245 2.19e-05 ***\nFin                 7.710e-01  3.966e-01   1.944 0.051913 .  \nA                   1.418e+00  3.958e-01   3.582 0.000341 ***\nEner                1.769e+00  3.960e-01   4.467 7.94e-06 ***\nInfo                3.904e-01  3.985e-01   0.979 0.327335    \nH                   1.155e+00  4.832e-01   2.391 0.016820 *  \nMulti               2.246e+00  6.367e-01   3.527 0.000420 ***\nPriv                8.699e+00  4.396e+01   0.198 0.843127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 200979  on 145306  degrees of freedom\nResidual deviance: 175595  on 145271  degrees of freedom\nAIC: 175667\n\nNumber of Fisher Scoring iterations: 7\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#predict probabilities for test subset (Warning)\nprobabilities1 <- log_model_train %>% predict(newdata=test_x.log, type = \"response\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n```\n:::\n\n```{.r .cell-code}\nhead(probabilities1) #the warning might be bc there is collinearity or too many predictors. \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        8        14        34        51        55        63 \n0.6394443 0.6120216 0.4675069 0.3935432 0.4991478 0.7957945 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#create predicted.classes1\npredicted.classes1 <- ifelse(probabilities1 > 0.5, 1, 0)\nhead(predicted.classes1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 8 14 34 51 55 63 \n 1  1  0  0  0  1 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Comparison between actual and predicted values\nmean(predicted.classes1 == test_y.log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6716011\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Check for aliased coeffs in the model\n\nalias(log_model_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel :\ntrain_y.log ~ AFR + EAP + ECA + LCR + MNA + SAR + ca_Consul.Service + \n    ca_Goods + ca_bids_all + ca_proc_open + ca_proc_quality + \n    ca_proc_source + ca_proc_restricted + singleb + corr_signp1 + \n    corr_signp2 + corr_signp3 + nrc + taxhaven + not.taxhaven + \n    cri_wb.d0 + cri_wb.d25 + cri_wb.d50 + cri_wb.d75 + P + Health + \n    Edu + W + I + Tran + Fin + A + Ener + Info + H + Multi + \n    Priv\n\nComplete :\n           (Intercept) AFR EAP ECA LCR MNA ca_Consul.Service ca_Goods\nSAR         1          -1  -1  -1  -1  -1   0                 0      \ncri_wb.d75  2           0   0   0   0   0   0                 0      \n           ca_bids_all ca_proc_open ca_proc_quality ca_proc_source\nSAR         0           0            0               0            \ncri_wb.d75  0           1            0               0            \n           ca_proc_restricted singleb corr_signp1 corr_signp2 corr_signp3 nrc\nSAR         0                  0       0           0           0           0 \ncri_wb.d75  0                 -1       1           0           0           0 \n           taxhaven not.taxhaven cri_wb.d0 cri_wb.d25 cri_wb.d50 P  Health Edu\nSAR         0        0            0         0          0          0  0      0 \ncri_wb.d75 -1        0           -4        -3         -2          0  0      0 \n           W  I  Tran Fin A  Ener Info H  Multi Priv\nSAR         0  0  0    0   0  0    0    0  0     0  \ncri_wb.d75  0  0  0    0   0  0    0    0  0     0  \n```\n:::\n\n```{.r .cell-code}\n#aliased coeffs indicate collinearity problem in the model (some variables are linearly dependent on others) and should be removed or transformed.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nalias(log_model_train)$reduced\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Remove cri_wb.d and other superfluous vars\n#Most probably cri_wb was calculated based on the other vars in the dataset, so it is linearly dependent on them and should be removed\ntrain_x.log2 = train_x.log %>% \n  select( -starts_with(\"cri_wb.d\"), -c(AFR, EAP, ECA, LCR, MNA, SAR, ca_bids_all)) #starts_with() removes all cri_wb dummies \n\ntest_x.log2 = test_x.log %>% \n  select( -starts_with(\"cri_wb.d\"), -c(AFR, EAP, ECA, LCR, MNA, SAR, ca_bids_all))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#2 logit model training\nlog_model_train.2 = glm(train_y.log ~ ., family = binomial(link = \"logit\"), train_x.log2)\nsummary(log_model_train.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = train_y.log ~ ., family = binomial(link = \"logit\"), \n    data = train_x.log2)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1247  -1.0546   0.5972   0.9890   2.3543  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        -4.547e-01  3.980e-01  -1.142 0.253301    \nca_Consul.Service  -1.164e+00  3.587e-02 -32.450  < 2e-16 ***\nca_Goods           -4.829e-01  1.515e-02 -31.880  < 2e-16 ***\nca_proc_open       -5.625e-01  3.864e-02 -14.559  < 2e-16 ***\nca_proc_quality    -7.681e-01  2.861e-02 -26.849  < 2e-16 ***\nca_proc_source     -8.259e-01  2.176e-02 -37.948  < 2e-16 ***\nca_proc_restricted -1.451e+00  4.600e-02 -31.536  < 2e-16 ***\nsingleb            -1.536e-01  1.412e-02 -10.880  < 2e-16 ***\ncorr_signp1         5.438e-01  1.899e-02  28.637  < 2e-16 ***\ncorr_signp2         3.407e-01  2.035e-02  16.740  < 2e-16 ***\ncorr_signp3         6.837e-01  2.421e-02  28.246  < 2e-16 ***\nnrc                 3.793e-05  1.264e-06  30.010  < 2e-16 ***\ntaxhaven            7.224e-01  4.179e-02  17.286  < 2e-16 ***\nnot.taxhaven        7.763e-01  1.460e-02  53.159  < 2e-16 ***\nP                   2.943e-01  3.954e-01   0.744 0.456650    \nHealth              9.874e-01  3.955e-01   2.496 0.012545 *  \nEdu                 1.335e+00  3.957e-01   3.373 0.000743 ***\nW                   1.257e+00  3.957e-01   3.176 0.001496 ** \nI                   6.348e-01  3.961e-01   1.603 0.109024    \nTran                1.625e+00  3.957e-01   4.108 3.99e-05 ***\nFin                 7.117e-01  3.966e-01   1.795 0.072714 .  \nA                   1.386e+00  3.958e-01   3.502 0.000461 ***\nEner                1.728e+00  3.960e-01   4.364 1.28e-05 ***\nInfo                3.181e-01  3.984e-01   0.798 0.424710    \nH                   1.137e+00  4.840e-01   2.349 0.018802 *  \nMulti               2.320e+00  6.344e-01   3.657 0.000255 ***\nPriv                8.504e+00  4.396e+01   0.193 0.846597    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 200979  on 145306  degrees of freedom\nResidual deviance: 176745  on 145280  degrees of freedom\nAIC: 176799\n\nNumber of Fisher Scoring iterations: 7\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nalias(log_model_train.2)$complete\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n```{.r .cell-code}\n#no aliased coeffs\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Predict probabilities2\nprobabilities2 <- log_model_train.2 %>% predict(newdata=test_x.log2, type = \"response\")\nhead(probabilities2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        8        14        34        51        55        63 \n0.6194700 0.5866468 0.4000703 0.3530457 0.4693526 0.7737040 \n```\n:::\n\n```{.r .cell-code}\n#No warning this time\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Predcited classes based on probabilities\npredicted.classes2 <- ifelse(probabilities2 > 0.5, 1, 0)\nhead(predicted.classes2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 8 14 34 51 55 63 \n 1  1  0  0  0  1 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Compare observed and predicted values\npred.rate.log = mean(predicted.classes2 == test_y.log)\n\nmean(predicted.classes2 == test_y.log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6688758\n```\n:::\n:::\n\n\n## KNN \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time = Sys.time()\n\n#KNN classification\n\nlibrary(class)\n\npredicted_labels = knn(train_x.log, test_x.log, train_y.log, k = 3)\n#Here I used the subsets with cri_wb and other coefficients because the model doesn't care about collinearity and because without them there were too many ties.\n\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 1.150231 mins\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Comparison between obs and predictions through KNN\npred.rate.knn = mean(predicted_labels == test_y.log)\n\nprint(pred.rate.knn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7562713\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted_labels2 = knn(train_x.log, test_x.log, train_y.log, k = 5)\n\npred.rate.knn2 = mean(predicted_labels2 == test_y.log)\nprint(pred.rate.knn2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7529266\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time = Sys.time()\n\n#KNN without cri_wb\ntrain_x.log3 = train_x.log %>% \n  select( -starts_with(\"cri_wb.d\")) #-starts_with() removes all cri_wb dummies \n\ntest_x.log3 = test_x.log %>% \n  select( -starts_with(\"cri_wb.d\"))\n\npredicted_labels3 = knn(train_x.log3, test_x.log3, train_y.log, k = 3)\n\npred.rate.knn3 = mean(predicted_labels3 == test_y.log)\nprint(pred.rate.knn3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7591205\n```\n:::\n\n```{.r .cell-code}\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 56.19445 secs\n```\n:::\n:::\n\n\n## Beyond Linearity: Splines\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#modelling basic spline without bids\n# Fit a regression model with cubic splines for multiple predictors\nspline_model <- lm(train_y ~ bs(nrc, degree = 3) + Edu + Ener + Multi, data = train_x)\nsummary(spline_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y ~ bs(nrc, degree = 3) + Edu + Ener + Multi, \n    data = train_x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.3907  -1.3039   0.0776   1.3431   9.4819 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          11.99366    0.01865 643.154   <2e-16 ***\nbs(nrc, degree = 3)1 -0.03461    0.06848  -0.505    0.613    \nbs(nrc, degree = 3)2  0.62123    0.06629   9.371   <2e-16 ***\nbs(nrc, degree = 3)3  0.87160    0.02672  32.625   <2e-16 ***\nEdu                   0.27344    0.01862  14.682   <2e-16 ***\nEner                  1.03912    0.02175  47.769   <2e-16 ***\nMulti                -0.21348    0.42393  -0.504    0.615    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.077 on 145300 degrees of freedom\nMultiple R-squared:  0.03805,\tAdjusted R-squared:  0.03801 \nF-statistic: 957.9 on 6 and 145300 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for basic spline\n\npreds_spline = predict(spline_model, test_x)\n\nrmse_spline = sqrt(mean(preds_spline - test_y)^2)\nsse_spline = sum((preds_spline - test_y)^2)\nhead(preds_spline)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       8       14       34       51       55       63 \n11.99398 12.26742 12.26742 12.00141 12.00141 12.00141 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(test_y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  8.978580 12.802028 13.114779  9.409601 12.325201 14.210191\n```\n:::\n\n```{.r .cell-code}\nsqrt(mean(preds_spline - test_y)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01513323\n```\n:::\n\n```{.r .cell-code}\nsum((preds_spline - test_y)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 70996.55\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(test_y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.6446 10.9005 12.3221 12.2694 13.6952 20.3544 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#spline model with bids included\nspline_model.bids <- lm(train_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + Edu + Ener + Multi, data = train_x)\nsummary(spline_model.bids)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, \n    degree = 3) + Edu + Ener + Multi, data = train_x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.3182  -1.2970   0.0857   1.3408   9.3605 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  11.90826    0.01882 632.741  < 2e-16 ***\nbs(nrc, degree = 3)1          0.01477    0.06829   0.216  0.82881    \nbs(nrc, degree = 3)2          0.53280    0.06617   8.052  8.2e-16 ***\nbs(nrc, degree = 3)3          0.84187    0.02665  31.586  < 2e-16 ***\nbs(ca_bids_all, degree = 3)1 11.07475    0.38349  28.879  < 2e-16 ***\nbs(ca_bids_all, degree = 3)2 -2.73186    1.81815  -1.503  0.13296    \nbs(ca_bids_all, degree = 3)3  2.58227    0.83824   3.081  0.00207 ** \nEdu                           0.24309    0.01860  13.072  < 2e-16 ***\nEner                          1.04128    0.02169  48.014  < 2e-16 ***\nMulti                        -0.20574    0.42263  -0.487  0.62639    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.07 on 145297 degrees of freedom\nMultiple R-squared:  0.04394,\tAdjusted R-squared:  0.04388 \nF-statistic:   742 on 9 and 145297 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#spline rmse and sse including bids variable\npreds_spline.bids = predict(spline_model.bids, test_x)\n\nrmse_spline.bids = sqrt(mean(preds_spline.bids - test_y)^2)\nsse_spline.bids = sum((preds_spline.bids - test_y)^2)\n\nprint(sse_spline.bids)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 70454.6\n```\n:::\n\n```{.r .cell-code}\nprint(rmse_spline.bids)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01356418\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot nrc vs value\nProcurement3 %>% \n  ggplot(aes(x=nrc, y=lca_contract_value)) +\n  geom_point() +\n  geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot nrc vs value-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot ca_bids_all vs value 1\nProcurement3 %>% \n  ggplot(aes(x=ca_bids_all, y=lca_contract_value)) +\n  geom_point() +\n  geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot ca_bids_all vs value 1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(train_x$nrc > 10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 23225\n```\n:::\n\n```{.r .cell-code}\nsum(train_x$ca_bids_all >= 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 294\n```\n:::\n\n```{.r .cell-code}\n293/145218\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002017656\n```\n:::\n\n```{.r .cell-code}\n23232/145218\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1599802\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot ca_bids_all vs value 2\nProcurement3 %>%\n  filter(!(ca_bids_all >= 50)) %>% \n  ggplot(aes(x=ca_bids_all, y=lca_contract_value)) +\n  geom_point() +\n  geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot ca_bids_all vs value 2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot for ca_bids_all\nProcurement3 %>% \n  filter(!(ca_bids_all >= 50)) %>%\n  ggplot(aes(x=ca_bids_all)) + \n  geom_histogram(binwidth = 1)\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot for ca_bids_all-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#scaling ca_bids_all & Creating Procure_scaled\nProcure_scaled = Procurement3 %>% \n  filter(!(ca_bids_all >= 50)) %>%\n  mutate_at(vars(ca_bids_all), scale) %>% \n  mutate_at(vars(ca_bids_all), as.numeric) #scale returns a matrix, so we need to save as.numeric\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot for nrc\nProcurement3 %>% \n  ggplot(aes(x=nrc)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot for nrc-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#scaling nrc\nProcure_scaled = Procure_scaled %>% \n  mutate_at(vars(nrc), scale) %>% \n  mutate_at(vars(nrc), as.numeric)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Checking scale\nhead(Procure_scaled$nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.8413083 -0.8413083 -0.8413083 -0.8413083 -0.8413083 -0.8413083\n```\n:::\n\n```{.r .cell-code}\nhead(Procure_scaled$ca_bids_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  0.5530255 -0.1404550 -0.1404550 -0.6027754  0.3218654  0.5530255\n```\n:::\n\n```{.r .cell-code}\nsummary(Procure_scaled$nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-1.0156 -0.6685 -0.4557  0.0000  0.2466  2.1803 \n```\n:::\n\n```{.r .cell-code}\nsummary(Procure_scaled$ca_bids_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.6028 -0.6028 -0.3716  0.0000  0.0907 10.2618 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(Procure_scaled$lca_contract_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n -3.632  10.933  12.344  12.286  13.681  21.480 \n```\n:::\n\n```{.r .cell-code}\nProcure_scaled = Procure_scaled %>% \n  filter(!is.na(lca_contract_value))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#assigning and sampling indices\nindex.spline = 1:nrow(Procure_scaled)\n\nset.seed(12345) #for random \ntrain_index.spline = sample(index.spline, round(0.90*nrow(Procure_scaled)), replace = FALSE) #takes sample of 90% of rows without replacement\n\ntest_index.spline = setdiff(index.spline, train_index.spline) #takes untaken rows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating train and test sets for spline\ntrain_x.sp = Procure_scaled[train_index.spline, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec) #Procure_scaled[train_index, ] expression to use only training subset %>% everything except price and price category\n\ntrain_y.sp = Procure_scaled[train_index.spline, ] %>% \n  pull(lca_contract_value)\n\ntest_x.sp = Procure_scaled[test_index.spline, ] %>% \n  select(-lca_contract_value, -ca_contract_valuec)\n\ntest_y.sp = Procure_scaled[test_index.spline, ] %>% \n  pull(lca_contract_value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#training spline regression model\nspline_model2 <- lm(train_y.sp ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + Edu + Ener + Multi, data = train_x.sp)\n#base spline with degree of polynomial 3. The resulting model will have a cubic polynomial function for each of the segments between the knots (which are quantiles by default).\nsummary(spline_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y.sp ~ bs(nrc, degree = 3) + bs(ca_bids_all, \n    degree = 3) + Edu + Ener + Multi, data = train_x.sp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.2785  -1.2860   0.0873   1.3266   8.8929 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  11.68783    0.01908 612.483  < 2e-16 ***\nbs(nrc, degree = 3)1          0.10699    0.06769   1.581    0.114    \nbs(nrc, degree = 3)2          0.40187    0.06573   6.114 9.74e-10 ***\nbs(nrc, degree = 3)3          0.74986    0.02645  28.347  < 2e-16 ***\nbs(ca_bids_all, degree = 3)1  3.52129    0.06223  56.588  < 2e-16 ***\nbs(ca_bids_all, degree = 3)2 -3.71759    0.16550 -22.463  < 2e-16 ***\nbs(ca_bids_all, degree = 3)3  0.90606    0.17384   5.212 1.87e-07 ***\nEdu                           0.23924    0.01849  12.941  < 2e-16 ***\nEner                          0.98373    0.02148  45.797  < 2e-16 ***\nMulti                        -0.24564    0.39442  -0.623    0.533    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.049 on 145002 degrees of freedom\nMultiple R-squared:  0.06263,\tAdjusted R-squared:  0.06257 \nF-statistic:  1076 on 9 and 145002 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#predictions by spline\npreds_spline2 = predict(spline_model2, test_x.sp)\n\nrmse_spline2 = sqrt(mean(preds_spline2 - test_y.sp)^2)\nhead(preds_spline2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       8       14       34       51       55       56 \n12.49270 12.33904 11.94622 12.11588 11.93343 12.11588 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for spline\nsse_spline2 = sum((preds_spline2 - test_y.sp)^2)\n\nprint(sse_spline2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 69440.65\n```\n:::\n\n```{.r .cell-code}\nprint(rmse_spline2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01712034\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#degree 1 to compare with spline degree 2\nspline_model.lr <- lm(train_y.sp ~ bs(nrc, degree = 1) + bs(ca_bids_all, degree = 1) + Edu + Ener + Multi, data = train_x.sp)\nsummary(spline_model.lr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y.sp ~ bs(nrc, degree = 1) + bs(ca_bids_all, \n    degree = 1) + Edu + Ener + Multi, data = train_x.sp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.3155  -1.2925   0.0838   1.3407   9.3581 \n\nCoefficients:\n                             Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)                 11.808730   0.008531 1384.211   <2e-16 ***\nbs(nrc, degree = 1)          0.888195   0.017549   50.612   <2e-16 ***\nbs(ca_bids_all, degree = 1)  1.883331   0.059426   31.692   <2e-16 ***\nEdu                          0.225089   0.018657   12.064   <2e-16 ***\nEner                         1.032723   0.021591   47.832   <2e-16 ***\nMulti                       -0.178013   0.398264   -0.447    0.655    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.069 on 145006 degrees of freedom\nMultiple R-squared:  0.04415,\tAdjusted R-squared:  0.04412 \nF-statistic:  1340 on 5 and 145006 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#predictions of spline degree 1\npreds_spline.lr = predict(spline_model.lr, test_x.sp)\n\nrmse_spline.lr = sqrt(mean(preds_spline.lr - test_y.sp)^2)\nhead(preds_spline.lr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       8       14       34       51       55       56 \n12.05751 12.16239 12.08225 11.97277 11.93270 11.97277 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for spline degree 1\nsqrt(mean(preds_spline.lr - test_y.sp)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01716597\n```\n:::\n\n```{.r .cell-code}\nsum((preds_spline.lr - test_y.sp)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 70568.34\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#breif check of predictions and obs\nsum(is.na(preds_spline2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\nsummary(preds_spline2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  11.05   11.81   12.15   12.29   12.65   14.43 \n```\n:::\n\n```{.r .cell-code}\nsummary(test_y.sp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.6561 10.9044 12.3478 12.2704 13.6981 20.3544 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#training spline using automatic knot selection gam\nlibrary(mgcv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: nlme\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'nlme'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:Ecdat':\n\n    Gasoline\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is mgcv 1.8-39. For overview type 'help(\"mgcv-package\")'.\n```\n:::\n\n```{.r .cell-code}\n# gam uses a built-in algorithm to choose optimal knots based on the data\nspline_model.gam <- gam(train_y.sp ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + Edu + Ener + Multi, data = train_x.sp)\nsummary(spline_model.gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntrain_y.sp ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + \n    Edu + Ener + Multi\n\nParametric coefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  11.68783    0.01908 612.483  < 2e-16 ***\nbs(nrc, degree = 3)1          0.10699    0.06769   1.581    0.114    \nbs(nrc, degree = 3)2          0.40187    0.06573   6.114 9.74e-10 ***\nbs(nrc, degree = 3)3          0.74986    0.02645  28.347  < 2e-16 ***\nbs(ca_bids_all, degree = 3)1  3.52129    0.06223  56.588  < 2e-16 ***\nbs(ca_bids_all, degree = 3)2 -3.71759    0.16550 -22.463  < 2e-16 ***\nbs(ca_bids_all, degree = 3)3  0.90606    0.17384   5.212 1.87e-07 ***\nEdu                           0.23924    0.01849  12.941  < 2e-16 ***\nEner                          0.98373    0.02148  45.797  < 2e-16 ***\nMulti                        -0.24564    0.39442  -0.623    0.533    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.0626   Deviance explained = 6.26%\nGCV = 4.1992  Scale est. = 4.1989    n = 145012\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for optimized-knots spline\npreds_spline.gam = predict(spline_model.gam, test_x.sp)\nrmse_spline.gam = sqrt(mean(preds_spline.gam - test_y.sp)^2)\nsse_spline.gam = sum((preds_spline.gam - test_y.sp)^2)\n\nprint(sse_spline.gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 69440.65\n```\n:::\n\n```{.r .cell-code}\nprint(rmse_spline.gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01712034\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#spline gam without removing outliers\nspline_model.gam2 <- gam(train_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + Edu + Ener + Multi, data = train_x)\nsummary(spline_model.gam2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntrain_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + \n    Edu + Ener + Multi\n\nParametric coefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  11.90826    0.01882 632.741  < 2e-16 ***\nbs(nrc, degree = 3)1          0.01477    0.06829   0.216  0.82881    \nbs(nrc, degree = 3)2          0.53280    0.06617   8.052  8.2e-16 ***\nbs(nrc, degree = 3)3          0.84187    0.02665  31.586  < 2e-16 ***\nbs(ca_bids_all, degree = 3)1 11.07475    0.38349  28.879  < 2e-16 ***\nbs(ca_bids_all, degree = 3)2 -2.73186    1.81815  -1.503  0.13296    \nbs(ca_bids_all, degree = 3)3  2.58227    0.83824   3.081  0.00207 ** \nEdu                           0.24309    0.01860  13.072  < 2e-16 ***\nEner                          1.04128    0.02169  48.014  < 2e-16 ***\nMulti                        -0.20574    0.42263  -0.487  0.62639    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.0439   Deviance explained = 4.39%\nGCV = 4.2859  Scale est. = 4.2856    n = 145307\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_spline.gam2 = predict(spline_model.gam2, test_x)\nrmse_spline.gam2 = sqrt(mean(preds_spline.gam2 - test_y)^2)\nsse_spline.gam2 = sum((preds_spline.gam2 - test_y)^2)\n\nprint(sse_spline.gam2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 70454.6\n```\n:::\n\n```{.r .cell-code}\nprint(rmse_spline.gam2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01356418\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#coefs of spline_model.gam\ncoef(spline_model.gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 (Intercept)         bs(nrc, degree = 3)1 \n                  11.6878264                    0.1069901 \n        bs(nrc, degree = 3)2         bs(nrc, degree = 3)3 \n                   0.4018697                    0.7498629 \nbs(ca_bids_all, degree = 3)1 bs(ca_bids_all, degree = 3)2 \n                   3.5212868                   -3.7175900 \nbs(ca_bids_all, degree = 3)3                          Edu \n                   0.9060622                    0.2392372 \n                        Ener                        Multi \n                   0.9837282                   -0.2456402 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot to compare with the previous one of nrc vs value\nProcurement3 %>% \n  ggplot(aes(x=nrc, y=lca_contract_value)) +\n  geom_point() +\n  geom_smooth(method = \"gam\", formula = y ~ s(x), se = FALSE)\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot to compare with the previous one of nrc vs value-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#compare with simple linear regression\nlr_check = lm(train_y.sp ~ nrc + ca_bids_all + Edu + Ener + Multi, data = train_x.sp)\nsummary(lr_check)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = train_y.sp ~ nrc + ca_bids_all + Edu + Ener + Multi, \n    data = train_x.sp)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.3155  -1.2925   0.0838   1.3407   9.3581 \n\nCoefficients:\n             Estimate Std. Error  t value Pr(>|t|)    \n(Intercept) 12.195462   0.005944 2051.686   <2e-16 ***\nnrc          0.277917   0.005491   50.612   <2e-16 ***\nca_bids_all  0.173347   0.005470   31.692   <2e-16 ***\nEdu          0.225089   0.018657   12.064   <2e-16 ***\nEner         1.032723   0.021591   47.832   <2e-16 ***\nMulti       -0.178013   0.398264   -0.447    0.655    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.069 on 145006 degrees of freedom\nMultiple R-squared:  0.04415,\tAdjusted R-squared:  0.04412 \nF-statistic:  1340 on 5 and 145006 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for linear reg\npreds_lrcheck = predict(lr_check, test_x.sp)\n\nrmse_lrcheck = sqrt(mean(preds_lrcheck - test_y.sp)^2)\n\nsqrt(mean(preds_lrcheck - test_y.sp)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01716597\n```\n:::\n\n```{.r .cell-code}\nsum((preds_lrcheck - test_y.sp)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 70568.34\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#gam spline with all vars\nspline_model.gam3 <- gam(train_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + AFR +EAP +ECA +LCR +MNA +SAR + ca_Consul.Service + ca_Goods + ca_proc_open + ca_proc_quality + ca_proc_source + ca_proc_restricted + corr_signp1 +corr_signp2 + corr_signp3 + taxhaven + not.taxhaven + P + Health + Edu + W + I + Tran + Fin + A + Ener + Info + H + Multi + Priv, data = train_x)\n\nsummary(spline_model.gam3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ntrain_y ~ bs(nrc, degree = 3) + bs(ca_bids_all, degree = 3) + \n    AFR + EAP + ECA + LCR + MNA + SAR + ca_Consul.Service + ca_Goods + \n    ca_proc_open + ca_proc_quality + ca_proc_source + ca_proc_restricted + \n    corr_signp1 + corr_signp2 + corr_signp3 + taxhaven + not.taxhaven + \n    P + Health + Edu + W + I + Tran + Fin + A + Ener + Info + \n    H + Multi + Priv\n\nParametric coefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  10.24556    0.22866  44.806  < 2e-16 ***\nbs(nrc, degree = 3)1          0.83188    0.07045  11.807  < 2e-16 ***\nbs(nrc, degree = 3)2          0.64910    0.07630   8.507  < 2e-16 ***\nbs(nrc, degree = 3)3          0.71961    0.02955  24.356  < 2e-16 ***\nbs(ca_bids_all, degree = 3)1 -0.07827    0.36783  -0.213  0.83150    \nbs(ca_bids_all, degree = 3)2  6.43106    1.63680   3.929 8.53e-05 ***\nbs(ca_bids_all, degree = 3)3 -0.64031    0.75370  -0.850  0.39557    \nAFR                           1.82642    0.03962  46.100  < 2e-16 ***\nEAP                           1.70413    0.04063  41.944  < 2e-16 ***\nECA                           1.63749    0.03979  41.158  < 2e-16 ***\nLCR                           1.30747    0.03976  32.884  < 2e-16 ***\nMNA                           1.98542    0.04169  47.623  < 2e-16 ***\nSAR                           1.78463    0.04135  43.156  < 2e-16 ***\nca_Consul.Service            -1.26199    0.03122 -40.428  < 2e-16 ***\nca_Goods                     -0.63796    0.01323 -48.204  < 2e-16 ***\nca_proc_open                 -0.42812    0.03361 -12.739  < 2e-16 ***\nca_proc_quality              -0.91561    0.02399 -38.174  < 2e-16 ***\nca_proc_source               -0.76538    0.01804 -42.417  < 2e-16 ***\nca_proc_restricted           -1.38403    0.03981 -34.767  < 2e-16 ***\ncorr_signp1                   0.53926    0.01612  33.450  < 2e-16 ***\ncorr_signp2                   0.32408    0.01723  18.805  < 2e-16 ***\ncorr_signp3                   0.75086    0.02056  36.521  < 2e-16 ***\ntaxhaven                      0.86965    0.03552  24.482  < 2e-16 ***\nnot.taxhaven                  0.83840    0.01265  66.259  < 2e-16 ***\nP                            -0.16916    0.26336  -0.642  0.52066    \nHealth                        0.42271    0.26350   1.604  0.10867    \nEdu                           0.70060    0.26369   2.657  0.00789 ** \nW                             0.79292    0.26368   3.007  0.00264 ** \nI                             0.15557    0.26414   0.589  0.55589    \nTran                          1.27607    0.26362   4.841 1.30e-06 ***\nFin                           0.15867    0.26461   0.600  0.54876    \nA                             0.82551    0.26374   3.130  0.00175 ** \nEner                          1.34328    0.26388   5.090 3.58e-07 ***\nInfo                         -0.04931    0.26670  -0.185  0.85333    \nH                             0.70120    0.36051   1.945  0.05178 .  \nMulti                         0.15113    0.46191   0.327  0.74352    \nPriv                          1.80728    1.87819   0.962  0.33593    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nRank: 36/37\nR-sq.(adj) =  0.229   Deviance explained = 22.9%\nGCV = 3.4586  Scale est. = 3.4577    n = 145307\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for spline with all vars\npreds_spline.gam3 = predict(spline_model.gam3, test_x)\n\nrmse_sp.gam3 = sqrt(mean(preds_spline.gam3 - test_y)^2)\nsse_sp.gam3  = sum((preds_spline.gam3 - test_y)^2)\n\nprint(rmse_sp.gam3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01400472\n```\n:::\n\n```{.r .cell-code}\nprint(sse_sp.gam3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 56856.29\n```\n:::\n:::\n\n\n\n## Regression Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(Procurement3)) #no missing values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#libraries for Trees\nlibrary(rpart)\nlibrary(rpart.plot) #prettier plots for rpart\nlibrary(tibble)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#checking the structure of the dataset\nstr(Procurement3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t161452 obs. of  39 variables:\n $ ca_contract_valuec: chr  \"50.000-199.999\" \"200.000-\" \"200.000-\" \"200.000-\" ...\n $ lca_contract_value: num  12 12.4 12.3 13.5 11.3 ...\n $ AFR               : num  1 1 1 1 1 1 1 1 1 1 ...\n $ EAP               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ECA               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ LCR               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ MNA               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ SAR               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ca_Consul.Service : num  0 0 0 1 0 0 0 0 0 0 ...\n $ ca_Goods          : num  0 0 0 0 1 0 1 1 1 1 ...\n $ ca_bids_all       : int  6 3 3 1 5 6 1 6 5 2 ...\n $ ca_proc_open      : num  1 1 1 0 1 1 0 1 1 1 ...\n $ ca_proc_quality   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ca_proc_source    : num  0 0 0 1 0 0 1 0 0 0 ...\n $ ca_proc_restricted: num  0 0 0 0 0 0 0 0 0 0 ...\n $ singleb           : num  0 0 0 1 0 0 1 0 0 0 ...\n $ corr_signp1       : num  1 0 0 0 1 0 0 1 1 0 ...\n $ corr_signp2       : int  0 0 0 0 0 0 1 0 0 1 ...\n $ corr_signp3       : int  0 0 0 1 0 0 0 0 0 0 ...\n $ nrc               : int  858 858 858 858 858 858 858 858 858 858 ...\n $ taxhaven          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ not.taxhaven      : num  0 0 0 1 1 0 1 1 1 0 ...\n $ cri_wb.d0         : num  1 0 0 0 1 0 0 1 1 0 ...\n $ cri_wb.d25        : num  0 1 1 0 0 1 0 0 0 1 ...\n $ cri_wb.d50        : num  0 0 0 0 0 0 0 0 0 0 ...\n $ cri_wb.d75        : num  0 0 0 1 0 0 1 0 0 0 ...\n $ P                 : num  1 0 0 0 0 1 0 0 0 0 ...\n $ Health            : num  0 1 0 0 0 0 1 0 0 0 ...\n $ Edu               : num  0 0 1 0 0 0 0 0 0 0 ...\n $ W                 : num  0 0 0 1 0 0 0 0 0 0 ...\n $ I                 : num  0 0 0 0 1 0 0 1 0 0 ...\n $ Tran              : num  0 0 0 0 0 0 0 0 1 0 ...\n $ Fin               : num  0 0 0 0 0 0 0 0 0 1 ...\n $ A                 : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Ener              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Info              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ H                 : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Multi             : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Priv              : num  0 0 0 0 0 0 0 0 0 0 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:13] 59655 59815 138472 138473 138474 138475 138476 138477 138478 138479 ...\n  ..- attr(*, \"names\")= chr [1:13] \"59655\" \"59815\" \"138472\" \"138473\" ...\n```\n:::\n:::\n\n\nWe need to recode dummies as factors for the decision tree.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#changing dummies from numeric to factor\ncols_for_factor <- c(\"AFR\", \"EAP\", \"ECA\", \"LCR\", \"MNA\", \"SAR\", \"ca_Consul.Service\", \"ca_Goods\", \"ca_proc_open\", \"ca_proc_quality\", \"ca_proc_source\", \"ca_proc_restricted\", \"singleb\", \"corr_signp1\", \"corr_signp2\", \"corr_signp3\", \"taxhaven\", \"not.taxhaven\", \"P\", \"Health\", \"Edu\", \"W\", \"I\", \"Tran\", \"Fin\", \"A\", \"Ener\", \"Info\", \"H\", \"Multi\", \"Priv\")\n\nProcurement5 <- Procurement3 %>%\n  select( -starts_with(\"cri_wb.d\"), -ca_contract_valuec) %>% \n  mutate_at(all_of(vars(cols_for_factor)), factor)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `all_of()` outside of a selecting function was deprecated in tidyselect\n1.2.0.\nℹ See details at\n  <https://tidyselect.r-lib.org/reference/faq-selection-context.html>\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(cols_for_factor)\n\n  # Now:\n  data %>% select(all_of(cols_for_factor))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n```\n:::\n\n```{.r .cell-code}\n#Procure_scaled2[cols_for_factor] = lapply(Procure_scaled[cols_for_factor], factor)\n#Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0. Please use `all_of()` or `any_of()` instead.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(Procurement5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t161452 obs. of  34 variables:\n $ lca_contract_value: num  12 12.4 12.3 13.5 11.3 ...\n $ AFR               : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 2 2 2 2 ...\n $ EAP               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ ECA               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ LCR               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ MNA               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ SAR               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ ca_Consul.Service : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 1 1 1 1 ...\n $ ca_Goods          : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 2 2 2 2 ...\n $ ca_bids_all       : int  6 3 3 1 5 6 1 6 5 2 ...\n $ ca_proc_open      : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 2 2 1 2 2 2 ...\n $ ca_proc_quality   : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ ca_proc_source    : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 2 1 1 1 ...\n $ ca_proc_restricted: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ singleb           : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 2 1 1 1 ...\n $ corr_signp1       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 2 1 1 2 2 1 ...\n $ corr_signp2       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 2 1 1 2 ...\n $ corr_signp3       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 1 1 1 1 ...\n $ nrc               : int  858 858 858 858 858 858 858 858 858 858 ...\n $ taxhaven          : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ not.taxhaven      : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 2 1 2 2 2 1 ...\n $ P                 : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 2 1 1 1 1 ...\n $ Health            : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 1 1 2 1 1 1 ...\n $ Edu               : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 1 1 1 1 1 ...\n $ W                 : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 1 1 1 1 ...\n $ I                 : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 2 1 1 ...\n $ Tran              : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 2 1 ...\n $ Fin               : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 2 ...\n $ A                 : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Ener              : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Info              : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ H                 : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Multi             : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Priv              : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:13] 59655 59815 138472 138473 138474 138475 138476 138477 138478 138479 ...\n  ..- attr(*, \"names\")= chr [1:13] \"59655\" \"59815\" \"138472\" \"138473\" ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#assigning and sampling indices for tree model\nindex.t = 1:nrow(Procurement5)\n\nset.seed(12345) #for random \ntrain_index.t = sample(index.t, round(0.90*nrow(Procurement4)), replace = FALSE) #takes sample of 90% of rows without replacement\n\ntest_index.t = setdiff(index.t, train_index.t) #takes untaken rows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating train and test sets for tree model\ntrain_x.t = Procurement5[train_index.t, ] %>% \n  select(-lca_contract_value) #Procure_scaled[train_index, ] expression to use only training subset %>% everything except price and price category\n\ntrain_y.t = Procurement5[train_index.t, ] %>% \n  pull(lca_contract_value)\n\ntest_x.t = Procurement5[test_index.t, ] %>% \n  select(-lca_contract_value)\n\ntest_y.t = Procurement5[test_index.t, ] %>% \n  pull(lca_contract_value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#first regression tree model\ntree_model <- rpart(\n  formula = train_y.t ~ .,\n  data    = train_x.t,\n  method  = \"anova\"\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot for the first tree\nrpart.plot(tree_model, digits = 4)\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/plot for the first tree-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#digits = The number of significant digits in displayed numbers\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#structure of the tree\ntree_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nn= 145307 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 145307 651308.50 12.28944  \n   2) ca_proc_open=0 64392 263413.50 11.67573  \n     4) not.taxhaven=0 43530 174856.70 11.34876  \n       8) nrc< 4495.5 32645 124934.50 11.12766  \n        16) AFR=0 23100  90592.66 10.81381 *\n        17) AFR=1 9545  26559.77 11.88722 *\n       9) nrc>=4495.5 10885  43540.74 12.01183 *\n     5) not.taxhaven=1 20862  74191.81 12.35800 *\n   3) ca_proc_open=1 80915 344342.10 12.77783  \n     6) P=1 22287  76991.40 11.79576 *\n     7) P=0 58628 237684.10 13.15116  \n      14) Tran=0 48010 179324.80 12.97448  \n        28) Ener=0 41969 148938.10 12.82764 *\n        29) Ener=1 6041  23194.13 13.99469 *\n      15) Tran=1 10618  50084.31 13.95003 *\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot size of the tree\nplotcp(tree_model)\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/plot size of the tree-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#To compare the error for each alpha value, rpart performs a 10-fold cross validation so that the error associated with a given alpa value is computed on the hold-out validation data.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#cptable for the first tree\ntree_model$cptable\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          CP nsplit rel error    xerror        xstd\n1 0.06686981      0 1.0000000 1.0000376 0.004230378\n2 0.04554926      1 0.9331302 0.9331805 0.003978562\n3 0.02205551      2 0.8875809 0.8876452 0.003861356\n4 0.01270517      3 0.8655254 0.8656022 0.003788718\n5 0.01104325      4 0.8528203 0.8529071 0.003725318\n6 0.01087315      5 0.8417770 0.8448465 0.003705916\n7 0.01000000      7 0.8200307 0.8201653 0.003598033\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse of the first tree_model\npreds_tree = predict(tree_model, test_x.t)\n\nrmse_tree = sqrt(mean(preds_tree - test_y.t)^2)\nsse_tree = sum((preds_tree - test_y.t)^2)\nprint(rmse_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01486034\n```\n:::\n\n```{.r .cell-code}\nprint(sse_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60814.71\n```\n:::\n:::\n\n\n## Tuning Regression Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#expand grid of the minsplit and maxdepth\nhyper_grid.t <- expand.grid(\n  minsplit = seq(5, 20, 1),\n  maxdepth = seq(8, 15, 1)\n)\n#create a hyper parameter grid\n#minsplit is the minimum number of data points required to attempt a split in the tree. Default=20\n#maxdepth is the maximum number of internal nodes between the root node and the terminal nodes (leafs). Default=30\n```\n:::\n\n\nWARNING: Takes a lot of time to run\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#loop function for training trees\n\nstart_time = Sys.time()\n\ntree_models = list() #creates a list that will contain tree models\n\nfor (i in 1:nrow(hyper_grid.t)) {\n  \n  # gets minsplit, maxdepth values at row i in hyper_grid.t\n  minsplit = hyper_grid.t$minsplit[i]\n  maxdepth = hyper_grid.t$maxdepth[i]\n\n  # trains a model and stores in the tree_models list\n  # models[[i]] = rpart(...) assigns a trained decision tree model to i-th element.\n  tree_models[[i]] = rpart(\n    formula = train_y.t ~ .,\n    data    = train_x.t,\n    method  = \"anova\",\n    control = list(minsplit = minsplit, maxdepth = maxdepth)\n    )\n}\n\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 12.40899 mins\n```\n:::\n\n```{.r .cell-code}\n#took a lot of time to run\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Functions to get the parameters with lowest error\n# function to get optimal cp\nget_cp <- function(x) {\n  min    <- which.min(x$cptable[, \"xerror\"])\n  cp <- x$cptable[min, \"CP\"] \n}\n\n# function to get minimum error\nget_min_error <- function(x) {\n  min    <- which.min(x$cptable[, \"xerror\"])\n  xerror <- x$cptable[min, \"xerror\"] \n}\n\nhyper_grid.t %>%\n  mutate(\n    cp    = purrr::map_dbl(tree_models, get_cp),\n    error = purrr::map_dbl(tree_models, get_min_error)\n    ) %>%\n  arrange(error) %>%\n  top_n(-5, wt = error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  minsplit maxdepth   cp     error\n1        6       10 0.01 0.8200839\n2        9       15 0.01 0.8200990\n3       13        8 0.01 0.8200991\n4       17       15 0.01 0.8201020\n5       15       15 0.01 0.8201025\n```\n:::\n\n```{.r .cell-code}\n#Mutates hyper_grid.t and adds columns with cp and errors and then returns top 5 rows with the lowest error value.\n#purrr::map_dbl() takes two arguments: the first argument is the vector or list that we want to apply the function to, and the second argument is the function that we want to apply. It applies the function to each element and returns a double (numeric).\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#tuned regression tree\ntuned_tree <- rpart(\n    formula = train_y.t ~ .,\n    data    = train_x.t,\n    method  = \"anova\",\n    control = list(minsplit = 8, maxdepth = 13, cp = 0.01)\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#RMSE and SSE for the tuned tree\npreds_tree2 = predict(tuned_tree, test_x.t)\n\nrmse_tunedtree = sqrt(mean(preds_tree2 - test_y.t)^2)\nsse_tunedtree = sum((preds_tree2 - test_y.t)^2)\nprint(rmse_tunedtree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01486034\n```\n:::\n\n```{.r .cell-code}\nprint(sse_tunedtree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60814.71\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot for the tuned tree\nrpart.plot(tuned_tree, digits = 4)\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/plot for the tuned tree-1.png){width=672}\n:::\n:::\n\n\nAbsolutely no difference between the automatically optimized regression tree and the tuned one.\n\n## Bagging\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library ipred and carte for bagging\nlibrary(ipred)\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'caret'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#training first bagged model\nset.seed(123)\n\n# train bagged model\nbag_tree <- bagging(\n  formula = train_y.t ~ .,\n  data    = train_x.t,\n  coob    = TRUE,\n  importance = TRUE\n)\n\n#importance=TRUE computes and stores the variables' relative importance. \n\nbag_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nBagging regression trees with 25 bootstrap replications \n\nCall: bagging.data.frame(formula = train_y.t ~ ., data = train_x.t, \n    coob = TRUE, importance = TRUE)\n\nOut-of-bag estimate of root mean squared error:  1.9175 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot for var importance\nvarimp = varImp(bag_tree) #importance from caret package\nvarimp = rownames_to_column(varimp, var = \"variable\")\n\n# create bar plot of variable importance measures\nvarimp %>% \n  filter(Overall!=0) %>% \n  ggplot(aes(x = Overall, \n             xend = 0, \n             y = reorder(variable, Overall), \n             yend=variable)) +\n  geom_segment() +\n  geom_point() +\n  labs(title = \"Variable Importance Plot for Bagging Model\", x = \"Importance\", y = \"Variables\")\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/plot for var importance-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#geom_bar(stat = \"identity\", fill = \"steelblue\") +\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for default bagging (first bagtree)\npreds_tree3 = predict(bag_tree, test_x.t)\n\nrmse_bagtree = sqrt(mean(preds_tree3 - test_y.t)^2)\nsse_bagtree = sum((preds_tree3 - test_y.t)^2)\nprint(rmse_bagtree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01477689\n```\n:::\n\n```{.r .cell-code}\nprint(sse_bagtree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60813.53\n```\n:::\n:::\n\n\nWARNING: Takes time to run\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#loop for plotting ntree vs rmse\n\nstart_time = Sys.time()\n\n# assess 10-50 bagged trees\nntree <- 10:50\n\n# create empty vector to store OOB RMSE values\nRMSE <- vector(mode = \"numeric\", length = length(ntree))\n\nfor (i in seq_along(ntree)) {\n  # reproducibility\n  set.seed(123)\n  \n  # training bagged models\n  bagged_models <- bagging(\n  formula = train_y.t ~ .,\n  data    = train_x.t,\n  coob    = TRUE,\n  nbagg   = ntree[i]\n)\n  # get OOB error\n  RMSE[i] <- bagged_models$err\n}\n\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 23.64319 mins\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot ntree vs RMSE\nplot(ntree, RMSE, type = 'l', lwd = 2)\nabline(v = 11, col = \"red\", lty = \"dashed\")\nabline(v = 25, col = \"blue\", lty = \"dashed\") #25 is default number of bootstraps\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/plot ntree vs RMSE-1.png){width=672}\n:::\n:::\n\n\nWe can see that the error drops and suddenly rises. After that the fall is slower. Given that 11 bootstraps give the lowest error before the default of 25, we can use it to reduce computation time. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmin(RMSE) #the minimum eror is not significantly lower\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.917357\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#training new bagged model\nset.seed(123)\n\n# train bagged model with 11 trees\nbag_tree2 <- bagging(\n  formula = train_y.t ~ .,\n  data    = train_x.t,\n  coob    = TRUE,\n  nbagg   = 11\n)\n\nbag_tree2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nBagging regression trees with 11 bootstrap replications \n\nCall: bagging.data.frame(formula = train_y.t ~ ., data = train_x.t, \n    coob = TRUE, nbagg = 11)\n\nOut-of-bag estimate of root mean squared error:  1.9174 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#rmse and sse for optimal bagging\npreds_tree4 = predict(bag_tree2, test_x.t)\n\nrmse_bagtree2 = sqrt(mean(preds_tree4 - test_y.t)^2)\nsse_bagtree2 = sum((preds_tree4 - test_y.t)^2)\nprint(rmse_bagtree2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01353659\n```\n:::\n\n```{.r .cell-code}\nprint(sse_bagtree2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60816.51\n```\n:::\n:::\n\n\n\n\n## Support Vector Machine\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library e1071 for SVM\nlibrary(e1071)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plotting nrc vs bidders and looking at classes\nProcurement3 %>% \n  filter(!(ca_bids_all >= 50)) %>% \n  mutate(above200k = recode_factor(ca_contract_valuec,\n                                \"200.000-\"=\"Yes\",\n                                .default = \"No\")) %>% \n  ggplot(aes(x=ca_bids_all, \n             y=nrc,\n             color=above200k)) +\n  geom_point(size = 2) +\n  scale_color_manual(values = c(\"#FF0000\", \"#000000\")) +\n  labs(title = \"Value\", x = \"bidders\", y = \"nrc\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plotting nrc vs bidders and looking at classes-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(Procure_scaled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t161125 obs. of  39 variables:\n $ ca_contract_valuec: chr  \"50.000-199.999\" \"200.000-\" \"200.000-\" \"200.000-\" ...\n $ lca_contract_value: num  12 12.4 12.3 13.5 11.3 ...\n $ AFR               : num  1 1 1 1 1 1 1 1 1 1 ...\n $ EAP               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ECA               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ LCR               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ MNA               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ SAR               : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ca_Consul.Service : num  0 0 0 1 0 0 0 0 0 0 ...\n $ ca_Goods          : num  0 0 0 0 1 0 1 1 1 1 ...\n $ ca_bids_all       : num  0.553 -0.14 -0.14 -0.603 0.322 ...\n $ ca_proc_open      : num  1 1 1 0 1 1 0 1 1 1 ...\n $ ca_proc_quality   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ca_proc_source    : num  0 0 0 1 0 0 1 0 0 0 ...\n $ ca_proc_restricted: num  0 0 0 0 0 0 0 0 0 0 ...\n $ singleb           : num  0 0 0 1 0 0 1 0 0 0 ...\n $ corr_signp1       : num  1 0 0 0 1 0 0 1 1 0 ...\n $ corr_signp2       : int  0 0 0 0 0 0 1 0 0 1 ...\n $ corr_signp3       : int  0 0 0 1 0 0 0 0 0 0 ...\n $ nrc               : num  -0.841 -0.841 -0.841 -0.841 -0.841 ...\n $ taxhaven          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ not.taxhaven      : num  0 0 0 1 1 0 1 1 1 0 ...\n $ cri_wb.d0         : num  1 0 0 0 1 0 0 1 1 0 ...\n $ cri_wb.d25        : num  0 1 1 0 0 1 0 0 0 1 ...\n $ cri_wb.d50        : num  0 0 0 0 0 0 0 0 0 0 ...\n $ cri_wb.d75        : num  0 0 0 1 0 0 1 0 0 0 ...\n $ P                 : num  1 0 0 0 0 1 0 0 0 0 ...\n $ Health            : num  0 1 0 0 0 0 1 0 0 0 ...\n $ Edu               : num  0 0 1 0 0 0 0 0 0 0 ...\n $ W                 : num  0 0 0 1 0 0 0 0 0 0 ...\n $ I                 : num  0 0 0 0 1 0 0 1 0 0 ...\n $ Tran              : num  0 0 0 0 0 0 0 0 1 0 ...\n $ Fin               : num  0 0 0 0 0 0 0 0 0 1 ...\n $ A                 : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Ener              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Info              : num  0 0 0 0 0 0 0 0 0 0 ...\n $ H                 : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Multi             : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Priv              : num  0 0 0 0 0 0 0 0 0 0 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:13] 59655 59815 138472 138473 138474 138475 138476 138477 138478 138479 ...\n  ..- attr(*, \"names\")= chr [1:13] \"59655\" \"59815\" \"138472\" \"138473\" ...\n```\n:::\n:::\n\n\nWe need scaled data, because the svm models take very long to run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Procurement.svm\nProcurement.svm = Procure_scaled %>% \n  mutate(abv200k = factor(ifelse(ca_contract_valuec==\"200.000-\", 1, 0))) %>% \n  select(abv200k, \n         nrc, \n         ca_bids_all, \n         P) %>% \n  mutate_at(vars(ca_bids_all, nrc), \n            funs(as.numeric(.)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#subsetting data for svm\nidx.svm = 1:nrow(Procurement.svm)\n\nset.seed(12345) #for random\ntrain_idx.svm = sample(idx.svm, round(0.50*nrow(Procurement.svm)), replace = FALSE) #takes sample of 50% of rows without replacement\n\ntest_idx.svm = sample(setdiff(idx.svm, train_idx.svm), round(0.10*nrow(Procurement.svm))) #takes 10% from the remaining rows for test\n\ntune_idx.svm = sample(idx.svm, round(0.03*nrow(Procurement.svm)), replace = FALSE) #index of the obs that we will use for tuning. Only 3%, because it is very time-consuming.\n\ntest_idx.svm2 = sample(setdiff(idx.svm, tune_idx.svm), round(0.10*nrow(Procurement.svm)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Procurement.svm[train_idx.svm,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       abv200k        nrc ca_bids_all P\n122931       0 -0.4101392  1.01534588 0\n98909        1 -0.1583185 -0.14045500 0\n65611        1  0.9206223  0.09070517 0\n95847        1 -0.4101392  2.63346713 0\n91914        1 -0.7741290 -0.37161518 0\n62368        1  0.9206223 -0.14045500 0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#training first svm model\nset.seed(123)\n# sample training data and fit model\nsvm.m1 <- svm(abv200k~ ., data = Procurement.svm[train_idx.svm,], kernel = \"radial\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_svm1 = predict(svm.m1, newdata = Procurement.svm[test_idx.svm,])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(preds_svm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n119261 139363 107621 129186  93690  85110 \n     1      1      0      0      1      0 \nLevels: 0 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#pred.rate.svm\npred.rate.svm = mean(preds_svm1 == Procurement.svm[test_idx.svm,]$abv200k)\n\nprint(pred.rate.svm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6296549\n```\n:::\n:::\n\n\nWARNING: The next chunk is very time-consuming.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#tuning svm using tune function and ranges of pars\n\nstart_time = Sys.time()\n\nset.seed(12345)\nsvm.tune <- tune(svm, abv200k~., data = Procurement.svm[tune_idx.svm,], kernel = \"radial\",\n                 ranges = list(cost = c(0.1,1,10,100),\n                 gamma = c(0.25,0.5,1,2)))\n\nsvm.tune$best.model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nbest.tune(METHOD = svm, train.x = abv200k ~ ., data = Procurement.svm[tune_idx.svm, \n    ], ranges = list(cost = c(0.1, 1, 10, 100), gamma = c(0.25, 0.5, \n    1, 2)), kernel = \"radial\")\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  radial \n       cost:  1 \n\nNumber of Support Vectors:  3783\n```\n:::\n\n```{.r .cell-code}\n#Takes forever to run, I used a small sample to find the best model to save time.\n\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 3.309396 mins\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npreds_svm2 = predict(svm.tune$best.model, newdata = Procurement.svm[test_idx.svm2,])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#tuned pred.rate.svm2\n\npred.rate.svm2 = mean(preds_svm2 == Procurement.svm[test_idx.svm2,]$abv200k)\n\nprint(pred.rate.svm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6310204\n```\n:::\n:::\n\n\n## Comparing RMSE, SSE, & Prediction rate and Conclusion\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# creating Errdf\n\nrmse.var = c(rmse_r, new_rmse.r, rmse_spline.bids, rmse_sp.gam3, rmse_tunedtree, rmse_bagtree2)\nsse.var = c(sse_r, new_sse.r, sse_spline.bids, sse_sp.gam3, sse_tunedtree, sse_bagtree2)\nmodel.var = c(\"lm_ridge.c\", \"lm_ridge.c2\", \"spline_model.bids\", \"spline_model.gam3\", \"tuned_tree\", \"bag_tree2\")\n\nErrdf = data.frame(model.var, rmse.var, sse.var)\nErrdf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          model.var   rmse.var  sse.var\n1        lm_ridge.c 0.01447194 56996.77\n2       lm_ridge.c2 0.01409955 57044.26\n3 spline_model.bids 0.01356418 70454.60\n4 spline_model.gam3 0.01400472 56856.29\n5        tuned_tree 0.01486034 60814.71\n6         bag_tree2 0.01353659 60816.51\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot RMSE\n\nErrdf %>% \n  group_by(rmse.var, sse.var) %>% \n  ggplot(aes(x = rmse.var, \n             xend = 0.013, \n             y = reorder(model.var, desc(rmse.var)), \n             yend=model.var,\n             label=round(rmse.var, 4))) +\n  geom_segment() +\n  geom_point() +\n  geom_text(nudge_x = 0, nudge_y = 0.1) +\n  labs(title = \"RMSE by model\", x = \"RMSE\", y = \"Models\")\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot RMSE-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot SSE\n\nErrdf %>% \n  ggplot(aes(x = sse.var, \n             xend = 50000, \n             y = reorder(model.var, desc(sse.var)), \n             yend=model.var,\n             label=round(sse.var, 1))) +\n  geom_segment() +\n  geom_point() +\n  geom_text(nudge_x = 0, nudge_y = 0.1) +\n  labs(title = \"SSE by model\", x = \"SSE\", y = \"Models\")\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot SSE-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#creating Errdf2\n\npred.rate = c(pred.rate.log, pred.rate.knn3, pred.rate.svm2)\npred.model = c(\"log_model_train.2\", \"knn3\", \"svm.tune\")\n\nErrdf2 = data.frame(pred.rate, pred.model)\nErrdf2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pred.rate        pred.model\n1 0.6688758 log_model_train.2\n2 0.7591205              knn3\n3 0.6310204          svm.tune\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plot for classifications correctness rates\n\nErrdf2 %>% \n  ggplot(aes(pred.model, pred.rate, label = round(pred.rate, 2))) +\n  geom_bar(stat = \"identity\", width = 0.5) +\n  geom_text(nudge_x = 0, nudge_y = 0.05) +\n  labs(title = \"Prediction Rates\", x = \"Methods of Classification\", y = \"Correct Predictions\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/Plot for classifications correctness rates-1.png){width=672}\n:::\n:::\n\n\n\n\n## Further discussion\n\nThere is a variable for period between the time of award of the contract and the signing of the said contract. I excluded the variable for now, since there are many missing values and the effect on the value is unclear.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(Procurement$ca_signper)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Length     Class      Mode \n   248000 character character \n```\n:::\n\n```{.r .cell-code}\ntest = Procurement\ntest$ca_signper <- as.numeric(Procurement$ca_signper)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: NAs introduced by coercion\n```\n:::\n\n```{.r .cell-code}\nsummary(test$ca_signper)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's \n-29231.00      5.00     20.00     30.14     48.00   4384.00     11857 \n```\n:::\n\n```{.r .cell-code}\ntest = test %>% \n  filter(!is.na(cri_wb))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n4436/161465\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02747345\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  filter(!(ca_signper <= -500)) %>%\n  ggplot(aes(x=ca_signper)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  filter(!is.na(ca_signper)) %>% \n  filter(ca_signper <= -900) %>% \n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    n\n1 195\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  filter(!is.na(ca_signper)) %>% \n  filter(ca_signper >= -900) %>%\n  ggplot(aes(x=ca_signper, y=lca_contract_value)) +\n  geom_point() +\n  geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 13 rows containing non-finite values (stat_smooth).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 13 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](ml_procurement_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ml_procurement_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}